[{"content":" ✏️ 編集\nインターステラーのIMAX再上映を観てから、「時の流れ」がマイブームになっています。そんな中、次のアイデアが浮かんで「エモいな」と思ったのでこの記事で少し書いてみたいと思います。\nデータそのものは時の流れに逆らえない（ある瞬間に生成された集計結果を過去から利用することはできない）が、その集計ロジックは（大元のデータの構造やロジックに変更が入らない限り）いつ実行しても同じだから時間を超越できる。\n注意:\n「エモいな」という感情に任せて勢いで書いているので、実践で役に立つかは考慮していません（多分、やらないで済む方向に出来る限り頑張ったほうが良いと思います） そもそも普通にもっと良い方法があるかもしれませんので、その際はご指摘いただけると幸いです シチュエーション 今回、次のようなシチュエーションを考えます。\n元々、次のように並列でジョブが実行されているパイプラインがあったとします。\ngraph LR データ取り込みジョブ --\u003e データ集計ジョブ1 --\u003e データ設置ジョブ1 データ取り込みジョブ --\u003e データ集計ジョブ2 --\u003e データ設置ジョブ2 後からdbtを導入し、まずデータ集計ジョブ1をdbtに移行しました。続いてデータ集計ジョブ2もdbtに移行しようとしましたが、諸事情（◯時までに×××にデータを設置する必要があり、dbtに移行すると間に合わない、など）でできませんでした。\ngraph LR データ取り込みジョブ --\u003e dbt --\u003e データ設置ジョブ1 データ取り込みジョブ --\u003e データ集計ジョブ2 --\u003e データ設置ジョブ2 しかし、このままだと集計ロジックがdbtとデータ集計ジョブ2の2つに分散し、管理が煩雑になってしまいます。\nアイデア この問題に対し、次のアイデアで解決を試みてみます。\nデータ集計ジョブ2の集計ロジックを mart_for_job2 モデルとしてdbtに移行します。 mart_for_job2 モデルは集計ロジックの実装を mart_for_job2_view ビュー、実際のデータ保持を mart_for_job2 テーブルで行うようにします。データ集計ジョブ2は mart_for_job2_view ビューを呼び出すことで集計処理を行うようにします。\ngraph LR データ取り込みジョブ subgraph dbt stg_hoge stg_bar subgraph mart_for_job2モデル mart_for_job2_view mart_for_job2 end end データ設置ジョブ1 データ集計ジョブ2 データ設置ジョブ2 stg_hoge --\u003e mart_for_job2_view stg_bar --\u003e mart_for_job2_view mart_for_job2_view --\u003e mart_for_job2 データ取り込みジョブ --\u003e dbt --\u003e データ設置ジョブ1 データ取り込みジョブ --\u003e データ集計ジョブ2 --\u003e データ設置ジョブ2 mart_for_job2_view -. 呼び出し .-\u003e データ集計ジョブ2 こうすることで、ジョブが分かれていても集計ロジックはdbtへ集約させることができます。\n時間に着目して言い換えると、データ集計ジョブ2は本来 mart_for_job2 テーブルに格納されてからでないと使えないはずの集計結果をそれより前に使えていることになります。これは時の流れを超越したと言っても過言ではないでしょうか（過言）。\n実際に実装してみた 次のデータリネージを持つdbtプロジェクトを作成し、 order_items モデルをデータ集計ジョブ2で使う想定で order_items_view ビューを実装しました。\n実装したリポジトリがこちらです。\nhttps://github.com/yamamoto-yuta/dbt-cross-time-with-view\nアイデアの限界 共通データマートを使いたい場合、使いたいテーブルができるまでの全てのdbtモデルでビューを作成する必要があります。dbtの実行完了より先にデータ集計ジョブ2が動き始めるため、dbtで作成したテーブルは使えません。\n例えば、 mart_for_job2 モデルで共通データマートである dim_foo モデルを使いたい場合、次のようにする必要があります。\ngraph LR データ取り込みジョブ subgraph dbt stg_hoge stg_bar subgraph dim_fooモデル dim_foo_view dim_foo end subgraph mart_for_job2モデル mart_for_job2_view mart_for_job2 end end データ設置ジョブ1 データ集計ジョブ2 データ設置ジョブ2 stg_hoge --\u003e dim_foo_view stg_bar --\u003e dim_foo_view dim_foo_view --\u003e dim_foo dim_foo_view --\u003e mart_for_job2_view mart_for_job2_view --\u003e mart_for_job2 データ取り込みジョブ --\u003e dbt --\u003e データ設置ジョブ1 データ取り込みジョブ --\u003e データ集計ジョブ2 --\u003e データ設置ジョブ2 mart_for_job2_view -. 呼び出し .-\u003e データ集計ジョブ2 これにより、データリネージが本来より複雑になります。これはdbt docsの使い勝手やdbt testの行いやすさなどに影響を与える可能性があります。\nこのあたりはCustom Materializationを使えば（1つのdbtモデルでビューとテーブルの2つを実体化できるようなmaterializationを自作する、など）改善できるかもしれません（要検証）。\n結び この記事では、ビューを使ってジョブの実行順によらず集計ロジックをdbtへ集約するアイデアについて記しました。\n冒頭にも書いた通り、「エモいな」という感情に任せて勢いで書いてますし、多分やらないで済む方向で出来る限り頑張ったほうが良いと思います。\nとはいえ、今回挙げたシチュエーションに実際に陥ってしまったなど、何かしらお役に立てれば幸いです🙇\n","date":"2024-12-30T09:50:18Z","permalink":"https://yamamoto-yuta.github.io/p/dbt-cross-time-with-view/","title":"ビューを使ってジョブの実行順によらず集計ロジックをdbtへ集約するアイデア"},{"content":" ✏️ 編集\nやろうと思った理由 GitHub Copilotで書かせたクエリをBQコンソールへコピペするのも面倒になってきたため。\nやった方法 ディレクトリ構成 1 2 3 4 5 6 7 8 9 10 11 12 . |-- .vscode/ | |-- extensions.json | |-- settings.json | |-- queries/ | |-- \u0026lt;YOUR_PROJECT_DIR_1\u0026gt;/ | | |-- \u0026lt;YOUR_QUERY_1\u0026gt;.bqsql // BQのクエリは拡張子を.bqsqlにすること | | |-- ... | | | |-- ... | extensions.json 1 2 3 4 5 6 { \u0026#34;recommendations\u0026#34;: [ \u0026#34;minodisk.bigquery-runner\u0026#34;, // BigQuery runner \u0026#34;shinichi-takii.sql-bigquery\u0026#34;, // SQL syntax highlighting ] } settings.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \u0026#34;bigqueryRunner.projectId\u0026#34;: \u0026#34;YOUR_PROJECT_ID_1\u0026#34;, // デフォルトの請求先プロジェクト。アドホック用途でスロットに上限が設定されているプロジェクトなどがあればそれを設定すると良い \u0026#34;bigqueryRunner.tree.projectIds\u0026#34;: [ \u0026#34;YOUR_PROJECT_ID_2\u0026#34;, // よくテーブルを見に行くプロジェクトがあればここに追加しておくと、VSCodeからツリーで見れて便利 ... ], \u0026#34;[sql-bigquery]\u0026#34;: { \u0026#34;editor.tabSize\u0026#34;: 2 }, // （お好みで）.bqsqlファイルをデータベースアイコンにする \u0026#34;material-icon-theme.files.associations\u0026#34;: { \u0026#34;*.bqsql\u0026#34;: \u0026#34;database\u0026#34; } } その他、工夫点など linterやformatterはあえて設定していない。当初は設定していたが、フォーマット結果が気に入らないことが多かったので…。\n実際やってみての感想 一時クエリを保存しておけるため、分析業務中に別の分析業務が割り込んできた時の切り替えと作業復帰がしやすくなった。WebのBQコンソールだとクエリを保存しない限りは適当なタイミングで消えてしまって切り替えが面倒だったので、これはかなり助かっている。加えて、プロジェクトごとにフォルダを分けておけば、並行している分析業務の数が増えても切り替えやすいので、これも助かっている（そもそも並列数を増やさないようにするのが理想だが…）。\nただ、クエリ結果をスプレッドシートに出力してピボットテーブルなどで集計することが多かったので、VSCode上だとその操作ができないのが少し不便。現状はWebのBQコンソールから個人の実行履歴を見に行くことでカバーしている。まぁ毎回スプレッドシートへの出力を行っているわけではないので、意外とそこまで不便さは感じていない（どっかで見るべき実行履歴を間違えて事故りそう、というのはある）。この辺りは自力でなんとかなりそうだったらcontributeしてみようかな…。\n参考 VSCode ＋ BigQuery ＋ SQLFluff の環境構築 BigQuery Runner for VSCode の紹介 VSCodeでSQLフォーマットするなら「SQL Formatter VSCode」で決まり！ #VSCode - Qiita ","date":"2024-12-29T04:49:32Z","permalink":"https://yamamoto-yuta.github.io/p/run-bq-with-vscode/","title":"VSCodeでBigQuery実行環境を整える"},{"content":" ✏️ 編集\nタイトルの通り。ExcelファイルをGASでそのまま操作しようとすると次のエラーが出る。\n検証用スクリプト:\n1 2 3 4 5 6 7 8 9 const main = () =\u0026gt; { const spreadsheetId = \u0026#34;YOUR_SPREADSHEET_ID\u0026#34;; const spreadsheetFromSpreadsheet = SpreadsheetApp.openById(spreadsheetId); console.log(spreadsheetFromSpreadsheet.getName()); // スプレッドシートのファイル名が出力される const xlsxId = \u0026#34;YOUR_XLSX_ID\u0026#34;; const spreadsheetFromXlsx = SpreadsheetApp.openById(xlsxId); console.log(spreadsheetFromXlsx.getName()); // Exception: Service Spreadsheets failed while accessing document with id 1RgRpia4esAR9xXsoxs5xDZRlySzvGpsW. }; そのため、Excelファイルをスプレッドシートに変換する必要がある。調べると色々な方法が見つかるがどれも微妙にうまくいかなかったので、現時点でうまくいった方法を記載する（この方法もそのうち使えなくなるかもしれないが…）。\n「サービス」からDrive APIを有効にする（バージョンは現時点での最新版であるv3を使用する） 次のスクリプトを実行する 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 const main = () =\u0026gt; { const parentFolderId = \u0026#34;YOUR_PARENT_FOLDER_ID\u0026#34;; const xlsxId = \u0026#34;YOUR_XLSX_ID\u0026#34;; const xlsxFile = DriveApp.getFileById(xlsxId); const options = { name: xlsxFile.getName(), mimeType: MimeType.GOOGLE_SHEETS, parents: [parentFolderId] }; const spreadsheetFromXlsx = Drive.Files.create( options, xlsxFile.getBlob(), {supportsAllDrives: true} // 共有ドライブ内のファイルを操作する場合に必要 ref: https://developers.google.com/drive/api/guides/enable-shareddrives?hl=ja ); console.log(spreadsheetFromXlsx.getName()); // ファイル名が表示される }; ","date":"2024-12-29T02:38:10Z","permalink":"https://yamamoto-yuta.github.io/p/convert-xlsx-to-spreadsheet-with-gas/","title":"ExcelファイルをGASで操作する場合はスプレッドシートへの変換が必要（2024/12/29時点）"},{"content":" ✏️ 編集\n動機 Gmailに未読が溜まりまくる。なんとかしたい。Slackなら常に見てるからここに転送させれば解消できるのでは？\n方法 Gmailでラベルを振り分ける Slack Appを作成し、Bot Token Scopesに chat:write を追加してワークスペースへインストールする 通知先のチャンネルにインストールしたSlack Appを招待する GASのスクリプトプロパティに SLACK_BOT_USER_OAUTH_TOKEN を設定する 次のスクリプトを定期的に（自分は10分にしている）実行するトリガーを設定する 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 const main = () =\u0026gt; { forwardGmailToSlack(\u0026#39;label:\u0026lt;YOUR_LABEL\u0026gt; is:unread \u0026#39;, \u0026#39;YOUR_CHANNEL_ID\u0026#39;); forwardGmailToSlack(\u0026#39;is:unread \u0026#39;, \u0026#39;OTHERS_CHANNEL_ID\u0026#39;); // 先に分類可能な未読メールを転送させてから、最後に残った未読を転送させること }; const forwardGmailToSlack = (query, channel) =\u0026gt; { const threads = GmailApp.search(query); if (threads.length == 0) { Logger.log(`新規メッセージなし: ${query}`); return } // Logger.log(threads.length); threads.forEach((thread) =\u0026gt; { const messages = thread.getMessages(); // Logger.log(messages.length); messages.forEach((message) =\u0026gt; { const from = message.getFrom(); const subject = message.getSubject(); const body = message.getPlainBody(); const mailId = message.getId(); const received_date = message.getDate(); const profileId = 0; // デフォルトプロファイルを使用 const mailUrl = \u0026#39;https://mail.google.com/mail/u/\u0026#39;+ profileId + \u0026#39;/#inbox/\u0026#39; + mailId; try { // 件名をチャンネルに投稿 const subjectMessage = `*件名*: ${subject}\\n*送信者*: ${from}\\n*受信日時*: ${formatDate(received_date)}\\n*メールURL*: ${mailUrl}`; const subjectResponse = postToSlack(channel, subjectMessage); const threadTs = subjectResponse.ts; // 投稿されたメッセージのタイムスタンプ // 本文をスレッドに投稿 const bodyMessage = `*本文*:\\n${body}`; postToSlack(channel, bodyMessage, threadTs); // メールを既読に変更 message.markRead(); } catch (e) { Logger.log(`Slackへの送信エラー: ${e.message}`); } }); }); }; const postToSlack = (channel, text, threadTs = null) =\u0026gt; { const getSlackBotToken = () =\u0026gt; { const scriptProperties = PropertiesService.getScriptProperties(); const token = scriptProperties.getProperty(\u0026#39;SLACK_BOT_USER_OAUTH_TOKEN\u0026#39;); if (!token) { throw new Error(\u0026#39;スクリプトプロパティに SLACK_BOT_USER_OAUTH_TOKEN が見つかりません。\u0026#39;); } return token; }; const slackBotToken = getSlackBotToken(); const url = \u0026#39;https://slack.com/api/chat.postMessage\u0026#39;; const payload = { channel: channel, text: text, // 投稿するメッセージ }; // スレッドへの投稿 if (threadTs) { payload.thread_ts = threadTs; } const options = { method: \u0026#39;post\u0026#39;, contentType: \u0026#39;application/json\u0026#39;, headers: { \u0026#39;Authorization\u0026#39;: `Bearer ${slackBotToken}`, }, payload: JSON.stringify(payload), }; const response = UrlFetchApp.fetch(url, options); const result = JSON.parse(response.getContentText()); if (!result.ok) { throw new Error(`Slack投稿エラー: ${channel} ${text} ${result.error}`); } return result; }; const formatDate = (date) =\u0026gt; { const year = date.getFullYear(); const month = (\u0026#39;0\u0026#39; + (date.getMonth() + 1)).slice(-2); // 月を2桁にフォーマット const day = (\u0026#39;0\u0026#39; + date.getDate()).slice(-2); // 日を2桁にフォーマット const hours = (\u0026#39;0\u0026#39; + date.getHours()).slice(-2); // 時間を2桁にフォーマット const minutes = (\u0026#39;0\u0026#39; + date.getMinutes()).slice(-2); // 分を2桁にフォーマット return `${year}/${month}/${day} ${hours}:${minutes}`; }; こんな感じでSlackへ通知される。\nチャンネル:\nスレッド:\n","date":"2024-12-23T13:38:07Z","permalink":"https://yamamoto-yuta.github.io/p/gmail-to-slack-using-gas/","title":"GASを使って、Gmailに届いたメールをSlackへ転送する"},{"content":" ✏️ 編集\nBigQueryで JSON_EXTRACT_ARRAY() を使ってJSONの配列を展開する際、値が空配列の行が混じっているケースがある。\n1 2 3 4 [ {\u0026#34;id\u0026#34;: 1, \u0026#34;items\u0026#34;: [10, 20, 30]}, {\u0026#34;id\u0026#34;: 2, \u0026#34;items\u0026#34;: []} ] これを無邪気に JSON_EXTRACT_ARRAY() すると、空配列の行が存在しないことになってしまう。\nクエリ:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 WITH sample_data AS ( SELECT \u0026#39;{\u0026#34;id\u0026#34;: 1, \u0026#34;items\u0026#34;: [10, 20, 30]}\u0026#39; AS item_json UNION ALL SELECT \u0026#39;{\u0026#34;id\u0026#34;: 2, \u0026#34;items\u0026#34;: []}\u0026#39; ), final AS ( SELECT JSON_EXTRACT_SCALAR(item_json, \u0026#34;$.id\u0026#34;) AS id, item FROM sample_data, UNNEST(JSON_EXTRACT_ARRAY(item_json, \u0026#39;$.items\u0026#39;)) AS item ) SELECT * FROM final 実行結果:\n1 2 3 4 id\titem 1\t10 1\t20 1\t30 ChatGPT (chatgpt-4o-latest) に訊いてみたところ、要素数が0かどうかで処理を分けるという解決策を教えてくれた。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 WITH sample_data AS ( SELECT \u0026#39;{\u0026#34;id\u0026#34;: 1, \u0026#34;items\u0026#34;: [10, 20, 30]}\u0026#39; AS item_json UNION ALL SELECT \u0026#39;{\u0026#34;id\u0026#34;: 2, \u0026#34;items\u0026#34;: []}\u0026#39; ), final AS ( -- サブクエリは使わない方が良いが、ここまで一気にやらないと下記のエラーが出てしまうため例外的に使っている -- エラー文: Array cannot have a null element; error in writing field item_array SELECT id, IFNULL(item, NULL) AS item FROM ( SELECT JSON_EXTRACT_SCALAR(item_json, \u0026#34;$.id\u0026#34;) AS id, CASE WHEN ARRAY_LENGTH(JSON_EXTRACT_ARRAY(item_json, \u0026#39;$.items\u0026#39;)) = 0 THEN ARRAY\u0026lt;STRING\u0026gt;[NULL] ELSE JSON_EXTRACT_ARRAY(item_json, \u0026#39;$.items\u0026#39;) END AS item_array FROM sample_data ), UNNEST(item_array) AS item ) SELECT * FROM final 結果:\n1 2 3 4 5 id\titem 1\t10 1\t20 1\t30 2\tArray cannot have a null element なのに後続処理まで一気にやったら動くのは不思議な挙動だ…（BigQuery内部のクエリ最適化の都合だとは思うが…）。\n","date":"2024-11-01T15:02:19Z","permalink":"https://yamamoto-yuta.github.io/p/handling-empty-array-in-json-extract-array/","title":"値が空配列の場合を考慮したJSON_EXTRACT_ARRAY"},{"content":" ✏️ 編集\nMeta Queset3 を買ったので Immsersed を使って作業環境を作れないか試してみた。その時の作業ログをここへ残す。\n接続 接続は有線推奨。無線だとマウスカーソルの移動が少しラグい。頑張れば行けなくもないが、作業環境として使うには妥協できない遅延具合 有線接続は結構な頻度でうまくいかないことがあるので、Meta Quest3の再起動で暫定対応している メニュー 設定 スクリーン設定 スナップグリッド: ON OFFだとスクリーン配置を自力で微調整しないといけない＆自力調整は辛すぎることが分かったので… VRマウスカーソル: OFF ONだとテキスト入力時のマウスカーソルが黒一色になり、どこにいるのかわからなくなって地味に不便だったので スクリーンの角でリサイズ: ON 文字通りスクリーンの角でリサイズできるようになる。スマホのミラーリング画面はリサイズ必須なので重宝する スクリーンの解像度 基本デフォルトで大丈夫なはず 下手に高解像度に上げるとImmersedが固まるので、1920x1080あたりを上限に設定するのが良さそう そのため、物理スクリーンで拡大率や文字サイズを80%くらいにしている場合は90%くらいまで上げると良い（同じサイズ感では厳しい） スクリーン配置 スナップグリッドをONにしている場合は、距離と角度が調整できる。配置は上下左右固定。 自分的には次の設定がしっくりきた: 平面で角度MAX これが一番首振り角度が少なくて疲れにくい感じがしたので… その他 両手の親指と薬指を数秒くっつけるとハンドトラッキングをOFFにできる キーボードやトラックパッドの操作で割と誤反応するので、OFFにしておくのが良い スマホ版Immersedを入れることでミラーリングができる 画質は良い 画面や音声がしょっちゅう固まる…おそらく回線が悪いせい… 操作はスマホで行う必要がある なので。ゲームには向かない。漫画とか読むのに使うのが良さそう？ 参考 【immersed 基本的な使い方】無料！日本語対応！VR・MRで最大5画面を空間配置し、動画編集ができる!! Meta Quest2、Quest3 、Quest pro、Pico4他対応 ","date":"2024-09-29T07:10:52Z","permalink":"https://yamamoto-yuta.github.io/p/meta-quest3-immsered-config-memo/","title":"Meta Queset3 + Immersed 設定メモ"},{"content":" ✏️ 編集\n今回、自分の github.io を Hugo に乗り換えた。テーマは Stack を選んだ。この記事では導入時のメモを残す。\nなお、次の記事が大変参考になった。\nHugo のインストール ローカルを汚したくなかったので Docker で環境構築を行うことにした。\napt install で入るが、そのままだとバージョンが古かったので、GitHub から最新版を取得してインストールした。\nDockerfile 1 2 3 4 5 6 7 8 9 10 FROM ubuntu:latest RUN apt-get update \u0026amp;\u0026amp; apt-get upgrade -y \\ \u0026amp;\u0026amp; apt-get install -y \\ git \\ curl RUN curl -L -o hugo_extended.deb https://github.com/gohugoio/hugo/releases/download/v0.129.0/hugo_extended_0.129.0_linux-arm64.deb \\ \u0026amp;\u0026amp; apt-get install -y ./hugo_extended.deb \\ \u0026amp;\u0026amp; rm hugo_extended.deb docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 services: site: build: . image: hugo env_file: - ./.env volumes: - .:/$WORKING_DIR working_dir: /$WORKING_DIR ports: - \u0026#34;1313:1313\u0026#34; tty: true 公式ドキュメント: Linux | Hugo\nHugo の初回セットとアップ 基本的には公式ドキュメントの Quickstart の通りに進めた。\nサイト名は blog に設定。\n1 hugo site new blog Stack テーマを submodule として追加。\n1 2 cd blog/ git submodule add https://github.com/CaiJimmy/hugo-theme-stack/ themes/hugo-theme-stack 以後、Dockerfile 等は blog/ にあったほうが都合が良いので移動。\n1 2 3 4 5 6 7 cd .. mv \\ .env \\ docker-compose.yml \\ Dockerfile \\ Makefile \\ blog/ Stack テーマはサンプルを用意してくれているので、それをベースに作成。\n1 2 3 4 5 cp -r \\ blog/themes/hugo-theme-stack/exampleSite/hugo.yaml \\ blog/themes/hugo-theme-stack/exampleSite/content \\ blog/themes/hugo-theme-stack/archetypes \\ blog/ 元々あった hugo.toml は先ほどコピーしたhugo.yamlに置き換わって不要になったので削除。\n1 rm blog/hugo.toml 参考:\nQuick start | Hugo Getting Started | Stack 非エンジニアの初心者が Hugo(テーマ Stack)+GitHub Pages でブログを開設するまで ローカルでの確認 ここまでで一旦 Hugo+Stack テーマの導入は完了したので、ローカルで動作確認を行った。コマンドは Makefile にまとめた。Docker 環境だとhugo server 時に --bind 0.0.0.0 を付けないと表示されないので注意。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 .PHONY: new-content new-content: @echo \u0026#39;Enter article title (e.g. \u0026#34;my-new-article\u0026#34;):\u0026#39; @read TITLE; docker compose run --rm site hugo new content content/post/$$TITLE/index.md .PHONY: server server: docker compose run --rm --service-ports site hugo server --bind 0.0.0.0 --buildDrafts .PHONY: server-prod server-prod: docker compose run --rm --service-ports site hugo server --bind 0.0.0.0 .PHONY: build build: docker compose run --rm site hugo --minify hugo.yaml の微調整 次の記事が参考になった。\n参考:\n非エンジニアの初心者が Hugo(テーマ Stack)+GitHub Pages でブログを開設するまで miiitomi.github.io/config.yaml at main · miiitomi/miiitomi.github.io 日本語フォントの変更 漢字が中国語フォントになっていたので日本語フォントに変更した。変更方法はlayouts/partials/head/custom.htmlを次の内容で作成することで行った。\nlayouts/partials/head/custom.html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;style\u0026gt; /* Overwrite CSS variable */ :root { --ja-font-family: \u0026#34;游ゴシック体\u0026#34;, \u0026#34;Yu Gothic\u0026#34;, YuGothic, \u0026#34;ヒラギノ角ゴ Pro\u0026#34;, \u0026#34;Hiragino Kaku Gothic Pro\u0026#34;, \u0026#34;メイリオ\u0026#34;, \u0026#34;Meiryo\u0026#34;; --base-font-family: \u0026#34;Lato\u0026#34;, var(--sys-font-family), var(--ja-font-family), sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;script\u0026gt; (function () { const customFont = document.createElement(\u0026#34;link\u0026#34;); customFont.href = \u0026#34;https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700\u0026amp;display=swap\u0026#34;; customFont.type = \u0026#34;text/css\u0026#34;; customFont.rel = \u0026#34;stylesheet\u0026#34;; document.head.appendChild(customFont); })(); \u0026lt;/script\u0026gt; 参考:\nCustom Header / Footer | Stack 非エンジニアの初心者が Hugo(テーマ Stack)+GitHub Pages でブログを開設するまで カスタムアイコンの追加 公式ドキュメント: Custom Menu | Stack\n埋め込みリンクの対応（断念） Hugo の Shortcodes を使ってはてなブログや Qiita のように簡単に埋め込みリンクを実現したかったが、想像以上に工数かかりそうだったのでので一旦 iframely で生成した DIV タグをそのまま貼り付けることにした。\n参考:\n自サービスに埋め込みコード対応をする方法 #oEmbed - Qiita デプロイ GitHub Actions を使って GitHub Pages にデプロイするように設定した。ワークフローは次のとおり。コメントのある箇所が注意点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 name: Deploy Hugo site to GitHub Pages on: push: branches: - main workflow_dispatch: jobs: deploy: runs-on: ubuntu-latest permissions: contents: write # Required for deploying to GitHub Pages steps: - name: Checkout repository uses: actions/checkout@v4 with: submodules: true # Fetch Hugo themes - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#34;latest\u0026#34; extended: true # Use Hugo extended version - name: Build Hugo site run: hugo --minify - name: Deploy to GitHub Pages uses: peaceiris/actions-gh-pages@v4 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_branch: gh-pages publish_dir: ./public 参考:\npeaceiris/actions-gh-pages: GitHub Actions for GitHub Pages 🚀 Deploy static files and publish your site easily. Static-Site-Generators-friendly. ","date":"2024-07-28T06:27:45Z","permalink":"https://yamamoto-yuta.github.io/p/hugo-stack-theme-installation-notes/","title":"Hugo+Stackテーマの導入メモ"},{"content":" ✏️ 編集\nこの前、 BigQuery で LEFT JOIN するクエリを書いていた時に少しつまづいたので、その時の調査結果を備忘録として残す（おそらく BigQuery に限らず SQL 全般の話だと思うので、記事タイトルは「SQL の」としている）。\n前提: 対象データ 次のような 3 つのテーブルを考える。\nLEFT JOIN してみる ① この 3 つのテーブルを JOIN して、 (item_key, item_code, shop_id) の組み合わせテーブルを作ることを考える。\n今回は次の 3 パターンの LEFT JOIN で実現してみる。\n次の順で LEFT JOIN する: ItemShops → Shops 次の順で LEFT JOIN する: Items → ItemShops → Shops 次の順で LEFT JOIN する: ItemShops → Shops → Items パターン 1: ItemShops → Shops クエリ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 WITH Items AS ( SELECT \u0026#39;xxx\u0026#39; AS item_key, \u0026#39;aaa\u0026#39; AS item_code UNION ALL SELECT \u0026#39;yyy\u0026#39;, \u0026#39;bbb\u0026#39; ), ItemShops AS ( SELECT \u0026#39;aaa\u0026#39; AS item_code, 1 AS shop_id UNION ALL SELECT \u0026#39;aaa\u0026#39;, 2 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 1 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 2 ), Shops AS ( SELECT 1 AS shop_id, \u0026#39;xxx\u0026#39; AS item_key UNION ALL SELECT 2, \u0026#39;yyy\u0026#39; ) SELECT C.item_key, B.item_code, B.shop_id FROM ItemShops B LEFT JOIN Shops C USING(shop_id) 結果:\n(item_key, item_code) の組み合わせがおかしい行が出てしまうため、この JOIN 方法では実現できない。\nパターン 2: Items → ItemShops → Shops クエリ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 WITH Items AS ( SELECT \u0026#39;xxx\u0026#39; AS item_key, \u0026#39;aaa\u0026#39; AS item_code UNION ALL SELECT \u0026#39;yyy\u0026#39;, \u0026#39;bbb\u0026#39; ), ItemShops AS ( SELECT \u0026#39;aaa\u0026#39; AS item_code, 1 AS shop_id UNION ALL SELECT \u0026#39;aaa\u0026#39;, 2 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 1 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 2 ), Shops AS ( SELECT 1 AS shop_id, \u0026#39;xxx\u0026#39; AS item_key UNION ALL SELECT 2, \u0026#39;yyy\u0026#39; ) SELECT A.item_key AS A_item_key, C.item_key AS C_item_key, B.item_code, B.shop_id, FROM Items A LEFT JOIN ItemShops B USING(item_code) LEFT JOIN Shops C USING(shop_id) 結果:\nA_item_key （＝ Items.item_key ）を採用しないと対応がおかしくなる。\nパターン 3: ItemShops → Shops → Items クエリ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 WITH Items AS ( SELECT \u0026#39;xxx\u0026#39; AS item_key, \u0026#39;aaa\u0026#39; AS item_code UNION ALL SELECT \u0026#39;yyy\u0026#39;, \u0026#39;bbb\u0026#39; ), ItemShops AS ( SELECT \u0026#39;aaa\u0026#39; AS item_code, 1 AS shop_id UNION ALL SELECT \u0026#39;aaa\u0026#39;, 2 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 1 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 2 ), Shops AS ( SELECT 1 AS shop_id, \u0026#39;xxx\u0026#39; AS item_key UNION ALL SELECT 2, \u0026#39;yyy\u0026#39; ) SELECT A.item_key AS A_item_key, C.item_key AS C_item_key, B.item_code, B.shop_id, FROM ItemShops B LEFT JOIN Shops C USING(shop_id) LEFT JOIN Items A USING(item_code) 結果:\nパターン 2 と同じ。\nLEFT JOIN してみる ② 何らかの理由で Items テーブルに存在しない item_key が Shops テーブルに組まれている状況を考える。\nShops.item_key = \u0026quot;yyy\u0026quot; は Items テーブルに存在しない。\nこの状況で、先ほどと同じ 3 パターンの LEFT JOIN を行ってみる。\nパターン 1: ItemShops → Shops クエリ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 WITH Items AS ( SELECT \u0026#39;xxx\u0026#39; AS item_key, \u0026#39;aaa\u0026#39; AS item_code ), ItemShops AS ( SELECT \u0026#39;aaa\u0026#39; AS item_code, 1 AS shop_id UNION ALL SELECT \u0026#39;aaa\u0026#39;, 2 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 1 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 2 ), Shops AS ( SELECT 1 AS shop_id, \u0026#39;xxx\u0026#39; AS item_key UNION ALL SELECT 2, \u0026#39;yyy\u0026#39; ) SELECT C.item_key, B.item_code, B.shop_id FROM ItemShops B LEFT JOIN Shops C USING(shop_id) 結果:\n存在しないはずの item_key = \u0026quot;yyy\u0026quot; の行が残っていたり、 (item_key, item_code) の組み合わせがおかしい行が存在していたりしており、適切な JOIN 方法ではないことがわかる。\nパターン 2: Items → ItemShops → Shops クエリ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 WITH Items AS ( SELECT \u0026#39;xxx\u0026#39; AS item_key, \u0026#39;aaa\u0026#39; AS item_code ), ItemShops AS ( SELECT \u0026#39;aaa\u0026#39; AS item_code, 1 AS shop_id UNION ALL SELECT \u0026#39;aaa\u0026#39;, 2 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 1 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 2 ), Shops AS ( SELECT 1 AS shop_id, \u0026#39;xxx\u0026#39; AS item_key UNION ALL SELECT 2, \u0026#39;yyy\u0026#39; ) SELECT A.item_key AS A_item_key, C.item_key AS C_item_key, B.item_code, B.shop_id, FROM Items A LEFT JOIN ItemShops B USING(item_code) LEFT JOIN Shops C USING(shop_id) 結果:\nA_item_key （＝ Items.item_key ）の方を採用すれば、この JOIN 方法で OK 。\nパターン 3: ItemShops → Shops → Items クエリ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 WITH Items AS ( SELECT \u0026#39;xxx\u0026#39; AS item_key, \u0026#39;aaa\u0026#39; AS item_code ), ItemShops AS ( SELECT \u0026#39;aaa\u0026#39; AS item_code, 1 AS shop_id UNION ALL SELECT \u0026#39;aaa\u0026#39;, 2 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 1 UNION ALL SELECT \u0026#39;bbb\u0026#39;, 2 ), Shops AS ( SELECT 1 AS shop_id, \u0026#39;xxx\u0026#39; AS item_key UNION ALL SELECT 2, \u0026#39;yyy\u0026#39; ) SELECT A.item_key AS A_item_key, C.item_key AS C_item_key, B.item_code, B.shop_id, FROM ItemShops B LEFT JOIN Shops C USING(shop_id) LEFT JOIN Items A USING(item_code) 結果:\n2 行目については A_item_key （＝ Items.item_key ）の方を採用しないと (item_key, item_code) の組み合わせがおかしくなるが、 3~4 行目に A_item_key IS NULL の行ができてしまっている。\nしたがって、この JOIN 方法は適切ではない。\n挙動の理解 上記挙動についての個人的な理解を以下に示す。\nLEFT JOIN してみる ① パターン 1: ItemShops → Shops\nパターン 2: Items → ItemShops → Shops\nパターン 3: ItemShops → Shops → Items\nLEFT JOIN してみる ② パターン 1: ItemShops → Shops\n「LEFT JOIN してみる ①」と同じ\nパターン 2: Items → ItemShops → Shops\nパターン 3: ItemShops → Shops → Items\n所感 LEFT JOIN するときは JOIN 順に気をつけよう（それはそう）\n","date":"2024-05-12T17:15:00Z","permalink":"https://yamamoto-yuta.github.io/p/sql-left-join-behavior-investigation-memo/","title":"SQL の LEFT JOIN の挙動についての調査メモ"},{"content":" ✏️ 編集\nClasp 環境から Slack API を使ってメッセージの送受信を行ってみたので、その時のメモを残す。\nClasp 環境は過去記事の環境を使用している。\nDocker で clasp 環境を構築する | yamamoto-yuta.github.io\nSlack App の作成 https://api.slack.com/apps から Slack App を作成する、\nOAuth \u0026amp; Permissions から下記の Scope を設定してワークスペースへインストールする。\nGAS でのメッセージ送受信部分の実装 Bot User Token と Slack App のメンバー ID を GAS のスクリプトプロパティに登録する。\nメッセージ送受信部分の実装は次のとおり。 main.ts の実装は下記記事のコードをほぼほぼベースにしている。\nSlack で動く ChatGPT のチャットボットを Google Apps Script（GAS）でサクッと作ってみる\nindex.ts :\n1 2 3 4 5 6 import { doPost } from \u0026#34;./main\u0026#34;; declare const global: any; // GAS において doPost() は特別な関数なので、global の名前は doPost にしておく必要がある global.doPost = doPost; main.ts :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 import URLFetchRequestOptions = GoogleAppsScript.URL_Fetch.URLFetchRequestOptions; // Slack へのメッセージ送信関数 const sendMessageToSlack = (channel: string, message: string) =\u0026gt; { const SLACK_BOT_TOKEN = PropertiesService.getScriptProperties().getProperty(\u0026#34;SLACK_BOT_TOKEN\u0026#34;); if (!SLACK_BOT_TOKEN) throw new Error(\u0026#34;SLACK_BOT_TOKEN is not set.\u0026#34;); const url = \u0026#34;https://slack.com/api/chat.postMessage\u0026#34;; const payload = { channel: channel, text: \u0026#34;echo: \u0026#34; + message, }; const options: URLFetchRequestOptions = { method: \u0026#34;post\u0026#34;, contentType: \u0026#34;application/json\u0026#34;, headers: { Authorization: `Bearer ${SLACK_BOT_TOKEN}` }, payload: JSON.stringify(payload), }; UrlFetchApp.fetch(url, options); }; export const doPost = (e: any) =\u0026gt; { const reqObj = JSON.parse(e.postData.getDataAsString()); // Slackから認証コードが送られてきた場合(初回接続時) // これをやっておかないと Event Subscriptions で URL が Verify されない if (reqObj.type == \u0026#34;url_verification\u0026#34;) { // 認証コードをそのまま返すことで、アプリをSlackに登録する処理が完了する return ContentService.createTextOutput(reqObj.challenge); } // Slackからのコールバック以外の場合、OKを返して処理を終了する if (reqObj.type !== \u0026#34;event_callback\u0026#34; || reqObj.event.type !== \u0026#34;message\u0026#34;) { return ContentService.createTextOutput(\u0026#34;OK\u0026#34;); } // メッセージが編集または削除された場合、OKを返して処理を終了する if (reqObj.event.subtype !== undefined) { return ContentService.createTextOutput(\u0026#34;OK\u0026#34;); } // Slackから送信されたトリガーメッセージ const triggerMsg = reqObj.event; // ユーザーID const userId = triggerMsg.user; // メッセージID const msgId = triggerMsg.client_msg_id; // チャンネルID const channelId = triggerMsg.channel; // タイムスタンプ const ts = triggerMsg.ts; // Bot自身によるメッセージである場合、OKを返して処理を終了する const SLACK_BOT_USER_ID = PropertiesService.getScriptProperties().getProperty(\u0026#34;SLACK_BOT_USER_ID\u0026#34;); if (!SLACK_BOT_USER_ID) throw new Error(\u0026#34;SLACK_BOT_USER_ID is not set.\u0026#34;); if (userId === SLACK_BOT_USER_ID) { return ContentService.createTextOutput(\u0026#34;OK\u0026#34;); } sendMessageToSlack(channelId, triggerMsg.text); return ContentService.createTextOutput(\u0026#34;OK\u0026#34;); }; Slack App の Event Subscription の設定 GAS 側が実装できたら、 GAS からウェブアプリとしてデプロイする。\nデプロイ後、ウェブアプリの URL を Slack App の Events Subscriptions の Request URL に貼り付ける。\n次の bot events を subscribe するよう設定する。\n実際に動かしてみる 作成した Slack App をチャンネルに招待してメッセージを送信すると、送信した文章を Slack App が echo するはず。\nローカルからデプロイする clasp deploy でローカルからデプロイできる。が、いくつか注意点がある。\n① appsscript.json に下記設定を追加しないと、「ウェブアプリ」ではなく「ライブラリ」としてデプロイされてしまう＝ウェブアプリの URL が発行されない\n1 2 3 4 \u0026#34;webapp\u0026#34;: { \u0026#34;access\u0026#34;: \u0026#34;ANYONE_ANONYMOUS\u0026#34;, \u0026#34;executeAs\u0026#34;: \u0026#34;USER_DEPLOYING\u0026#34; }, 設定内容は下記画像と同じ。\n② clasp deploy 時にデプロイ ID を指定しないと新しいデプロイが作成されてしまい、ウェブアプリの URL が変わってしまう（ → 公式ドキュメント ）\nclasp deployment でアクティブなデプロイの一覧が取得できる。再デプロイする場合、デプロイ一覧の中から最新のデプロイ ID を取得し、それを clasp deploy で指定する。今回は次のような再デプロイ用スクリプトを作成して対処した。\nredeploy.sh :\n1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash # Build yarn webpack --mode production # Push yarn clasp push # Get last deployment id LAST_DEPLOYMENT_ID=$(yarn clasp deployments | tail -n 2 | head -n 1 | awk \u0026#39;{print $2}\u0026#39;) # Deploy yarn clasp deploy --deploymentId $LAST_DEPLOYMENT_ID クリプトは次の記事が参考になった。\nGoogle Apps Script の Clasp で Web アプリの URL を変えないでデプロイする方法 - ある SE のつぶやき・改\n参考記事 Slack で動く ChatGPT のチャットボットを Google Apps Script（GAS）でサクッと作ってみる GAS ＋ clasp に npm のライブラリも使って slack アプリを作る #Slack - Qiita GAS Web app を Clasp からデプロイ #JavaScript - Qiita Google Apps Script の Clasp で Web アプリの URL を変えないでデプロイする方法 - ある SE のつぶやき・改 ","date":"2024-03-24T16:56:00Z","permalink":"https://yamamoto-yuta.github.io/p/clasp-slack-api-send-receive-messages/","title":"Clasp 環境下で Slack API を使ってメッセージを送受信する"},{"content":" ✏️ 編集\n買ったキーボード NuPhy Air75 V2 ワイヤレスメカニカルキーボード\n日本の販売ページ: Air75 V2 ワイヤレスメカニカルキーボード – Nuphy Japan NuPhy 公式販売ページ: NuPhy Air75 V2 QMK/VIA Wireless Custom Mechanical Keyboard キー割り当て 利用環境 キーボード: NuPhy Air75 V2 （US 配列） PC: Mac (JIS 配列) Windows （JIS 配列） Win/Mac のデバイス切り替え 下記ショートカットキーでデバイス切り替えが可能。\n1 FN + 1 / 2 / 3 / 4 = Bluetooth 1 / 2/ 3 / 2.4GHz 今回は FN + 1 を Mac 、 FN + 2 を Windows に割り当てた。\nまた、キーボードに Win/Mac の切り替えスイッチがあるので、接続先の PC に合わせてスイッチを切り替えることにした。\n（画像引用: NuPhy Air75 V2 QMK/VIA Wireless Custom Mechanical Keyboard）\nこれにより、 Windows と Mac で使用する VIA のレイヤーを切り替えることができる。\n（画像引用: VIA– SUPER KOPEK）\n参考: VIA– SUPER KOPEK\nMac でのキー割り当て Mac ではキーボードを繋ぐとダイアログが出てきて、その指示に従えば JIS/US を判別してくれる。そのため、繋ぐだけで最低限使える状態になった。\n以前のキーボードでは左キーを下記の配置で使っていた。\n1 Ctrl | Cmd | Opt そのため、 Air75 V2 でもキー割り当てを変更し、同じ配置にした。\nキー割り当ての変更は VIA で行った。\nNuPhy Air75 V2 における VIA を使ったキー割り当て変更については、次の公式ページに記載されている手順で行った。\n公式ページ: VIA Usage Guide for NuPhy Keyboards\n実際に割り当てた結果が次の画像。なお、 LWin = LCmd 、 LAlt = LOpt と対応している。\nキー割り当てに合わせて、キーキャップも入れ替えた（CMD と OPT のキーキャップが同じ形状で良かった…）。\nWin でのキー割り当て JIS 配列の Windows に US 配列のキーボードを繋ぐ方法はいくつかあるようだが、今回は ULE4JIS というフリーソフトを使う方法を採用した。理由は Capslock でかな/英字のモード切替を行いたかったから。\n参考: ノートパソコンは JIS 配列で外付けキーボードを US 配列に（Windows）\nMac の Cmd の位置に Win の Ctrl を置きたかったので、 VIA で次のように割り当てた。\n","date":"2024-03-22T17:27:00Z","permalink":"https://yamamoto-yuta.github.io/p/nuphy-air75-v2-keyboard-layout-memo/","title":"NuPhy Air75 V2 キーボードを買ったので、キー割り当てメモ"},{"content":" ✏️ 編集\nclasp 環境を Docker で作ってみたので、そのときの作業ログを以下に示す。\nClasp とは GAS をローカルで開発するためのツール。\n公式リポジトリ: google/clasp: 🔗 Command Line Apps Script Projects\n前準備: GAS API を有効化する ここから有効化できる: https://script.google.com/home/usersettings\n用意するファイルとディレクトリ構造 ディレクトリ構造:\n1 2 3 4 . |-- .gitignore |-- .env |-- docker-compose.yml 用意するファイル:\n.gitignore 1 2 3 4 5 6 7 .* .*/ node_modules/ dist/Code.gs !.gitignore !.*.sample 補足:\nCode.gs はビルド結果なので gitignore しておく .env 1 2 WORKING_DIR=/usr/src/app HOME=$WORKING_DIR 補足:\nclasp はログインの credential 情報をコンテナ内のユーザの $HOME 直下に作成する（ → 参考 ）ので、 $HOME を $WORKING_DIR にするよう設定している docker-compose.yml によってカレントディレクトリが $WORKING_DIR にマウントされる＝カレントディレクトリに credential 情報が書かれたドットファイルが置かれるが、 .gitignore で指定したドットファイル以外は gitignore するようにすることで誤 push を防いでいる docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 version: \u0026#34;3\u0026#34; services: app: image: node:20 container_name: docker_clasp_container env_file: - .env volumes: - ./:$WORKING_DIR working_dir: $WORKING_DIR tty: true 環境構築手順 コンテナを起動して中に入る・\n1 2 $ docker compose up -d $ docker exec -it \u0026lt;CONTAINER_ID\u0026gt; bash yarn init し、Clasp と TypeScript をインストールする。\n1 2 [In the container]# yarn init -y [In the container]# yarn add -D @google/clasp @types/google-apps-script typescript ts-loader clasp にログインする。\n1 2 3 4 5 6 [In the container]# yarn clasp login ① 出てきた URL にアクセス ② Google アカウントでログイン ③ localhost:*** という無効な URL に遷移すれば OK ④ 別ターミナルでコンテナ内に入り、 curl \u0026#39;さっきの無効な URL\u0026#39; ⑤ ターミナルにログイン成功の旨が出ていればOK 補足: なぜ別ターミナルで curl する必要があるのか？ どうやら clasp login の --no-localhost オプションがうまく機能しないらしいため。\nその回避策として別ターミナルで curl を叩く方法が紹介されていた（ → 参考 ）。\n今回、 --no-localhost オプションは使用していないが、同じ方法でログインできた。\n今回は スクリプト ID が \u0026lt;GAS_SCRIPT_ID\u0026gt; の GAS プロジェクトのソースコードを src/ ディレクトリに配置することにする。\nそのため、まず src/ ディレクトリを作成する。\n1 [In the container]# mkdir src 指定したスクリプト ID の GAS プロジェクトのコードをローカルへ clone する。\n1 [In the container]# yarn clasp clone \u0026lt;GAS_SCRIPT_ID\u0026gt; clone 後、次の 3 ファイルが生成される。\n1 2 3 4 5 . |-- src/ |-- .clasp.json |-- appsscript.json |-- \u0026lt;YOUR_GAS_SCRIPT\u0026gt;.js このうち、次の 2 ファイルを src/ へ移動させる。\n1 [In the container]# mv appsscript.json \u0026lt;YOUR_GAS_SCRIPT\u0026gt;.js src/ .clasp.json の rootDir を次のように変更する。\n1 2 - \u0026#34;rootDir\u0026#34;: \u0026#34;/usr/src/app\u0026#34; + \u0026#34;rootDir\u0026#34;: \u0026#34;/usr/src/app/src\u0026#34; clasp push で、ローカルのコードを GAS 上へ反映させる。\n1 [In the container]# yarn clasp push Web 上の GAS エディタのページをリロードすると、ローカルのコードが反映されているはず。\nES modules の利用 2024/03/18 現在、 GAS は ES modules に対応しておらず、 import などが使えない。\n使えるようにする方法はいくつかあるようだが、今回は gas-webpack-plugin を使ってみる。\nWebpack と gas-webpack-plugin をインストール。\n1 [In the container]# yarn add -D gas-webpack-plugin webpack webpack-cli 今回は src/ のソースコードをビルドして dist/ に置くことにする。\nそのため、まず dist/ を作成する。\n1 [In the container]# mkdir dist/ 続いて、 appsscript.json を dist/ へ移動させる。\n1 [In the container]# mv src/appsscript.json dist/ 併せて、 .clasp.json の rootDir を次のように変更する。\n1 2 - \u0026#34;rootDir\u0026#34;: \u0026#34;/usr/src/app/src\u0026#34; + \u0026#34;rootDir\u0026#34;: \u0026#34;/usr/src/app/dist\u0026#34; webpack.config.json を作成し、次の内容を設定する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 const path = require(\u0026#34;path\u0026#34;); const GasPlugin = require(\u0026#34;gas-webpack-plugin\u0026#34;); module.exports = { context: __dirname, entry: \u0026#34;./src/index.ts\u0026#34;, output: { path: path.join(__dirname, \u0026#34;dist\u0026#34;), filename: \u0026#34;Code.gs\u0026#34;, }, resolve: { extensions: [\u0026#34;.ts\u0026#34;, \u0026#34;.js\u0026#34;], }, module: { rules: [ { test: /\\.[tj]s$/, use: \u0026#34;ts-loader\u0026#34;, exclude: /node_modules/, }, ], }, plugins: [new GasPlugin()], }; この時点で、次のようなディレクトリ構造になっているはず。\n1 2 3 4 5 6 7 . |-- /dist | |-- appsscript.json |-- src/ | |-- \u0026lt;YOUR_GAS_SCRIPT\u0026gt;.js |-- .clasp.json |-- webpack.config.js yarn webpack でコードをビルドした後、 clasp push で、ローカルのコードを GAS 上へ反映させる。\n1 2 [In the container]# yarn webpack --mode production [In the container]# yarn clasp push Web 上でローカルのコードが確認できたら OK 。\nサンプルコード clasp create 等の際の動作確認用サンプルコードを以下に示す。\nディレクトリ構造:\n1 2 3 4 . |-- src/ |-- index.ts | |-- main.ts index.ts\n1 2 3 4 5 import { mainFunc } from \u0026#34;./main\u0026#34;; declare const global: any; global.mainFunc = mainFunc; main.ts\n1 export const mainFunc = () =\u0026gt; console.log(\u0026#34;Hello World\u0026#34;); TIPS こんな感じで Makefile に clasp push 用コマンドを登録しておくと、 make push で GAS へ push できて楽。\nMakefile\n1 2 3 .PHONY: push push: docker compose run --rm app bash -c \u0026#34;yarn webpack --mode production \u0026amp;\u0026amp; yarn clasp push\u0026#34; 参考記事 clasp を使って Google Apps Script の開発環境を構築してみた | DevelopersIO clasp で GAS を github 管理する gas を管理する clasp の docker 環境を作成する #Docker - Qiita clasp login \u0026ndash;no-localhost が使えない #GoogleAppsScript - Qiita GAS + Typescript のいい感じのビルド環境を整える [初心者向け] GoogleAppsScript(GAS)の開発環境をインクリメンタルに構築(TypeScript / Module / Polyfill) #Docker - Qiita ","date":"2024-03-03T16:13:00Z","permalink":"https://yamamoto-yuta.github.io/p/docker-clasp-environment-setup/","title":"Docker で clasp 環境を構築する"},{"content":" ✏️ 編集\nやったこと 次の記事で実装されていた SQL の CTE を可視化するツールが便利だった。\nhttps://note.com/dd_techblog/n/n3876f38cc5fc\nただ、記事では Python で実装されており、ツールを使うにはサーバを建てる必要があり少し面倒だった。なので、 GitHub Pages からサクッと使えるよう JavaScript で実装し直してみた。\n次のリンクから実際に触れる。\nhttps://yamamoto-yuta.github.io/sql-cte-visualizer-js/\n以下、試行錯誤したときのメモ\nPython → JavaScript への実装 先の記事 を自分で動かしてみた。そのときの GitHub リポジトリがこちら:\nhttps://github.com/yamamoto-yuta/sql-cte-visualizer?tab=readme-ov-file\nこの中の main.py コピーし、 ChatGPT へ「 JavaScript で書き直して」と指示することで、実装の叩きを作った。というか、可視化の部分以外はこれでいけた。\nSQL パーサーを用いたアプローチ 実は当初は記事にある正規表現ではなく SQL パーサーを用いた方法を検討していた。理由は ChatGPT に投げた際に Python → JavaScript の変換で正規表現部分がうまくいかなかったため（後にうまくいくことがわかったため、正規表現を用いた方法に戻した）。\nその際、 SQL パーサーは「 node-sql-parse 」というライブラリを採用した。\nhttps://github.com/taozhi8833998/node-sql-parser\n（SQL パーサーの選定には次の記事が参考になった）\nhttps://zenn.dev/carenet/articles/d42b236ae69bc5\nnode-sql-parser でのパースの例を以下に示す。\nSQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 -- 複数のCTEの定義 WITH DepartmentSummary AS ( SELECT department_id, department_name, COUNT(*) AS employee_count FROM departments GROUP BY department_id, department_name ), ProjectSummary AS ( SELECT project_id, project_name, COUNT(*) AS member_count FROM projects GROUP BY project_id, project_name ) -- 複数のCTEとJOINを使用したクエリ SELECT e.employee_id, e.employee_name, e.role, d.department_name, d.employee_count, p.project_name, p.member_count FROM employees e JOIN DepartmentSummary d ON e.department_id = d.department_id LEFT JOIN employee_projects ep ON e.employee_id = ep.employee_id LEFT JOIN ProjectSummary p ON ep.project_id = p.project_id; パース結果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 [ { \u0026#34;type\u0026#34;: \u0026#34;select\u0026#34;, \u0026#34;as_struct_val\u0026#34;: null, \u0026#34;distinct\u0026#34;: null, \u0026#34;columns\u0026#34;: [ { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;e\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;employee_id\u0026#34;, \u0026#34;subFields\u0026#34;: [] }, \u0026#34;as\u0026#34;: null }, { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;e\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;employee_name\u0026#34;, \u0026#34;subFields\u0026#34;: [] }, \u0026#34;as\u0026#34;: null }, { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;e\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;role\u0026#34;, \u0026#34;subFields\u0026#34;: [] }, \u0026#34;as\u0026#34;: null }, { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;d\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;department_name\u0026#34;, \u0026#34;subFields\u0026#34;: [] }, \u0026#34;as\u0026#34;: null }, { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;d\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;employee_count\u0026#34;, \u0026#34;subFields\u0026#34;: [] }, \u0026#34;as\u0026#34;: null }, { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;p\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;project_name\u0026#34;, \u0026#34;subFields\u0026#34;: [] }, \u0026#34;as\u0026#34;: null }, { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;p\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;member_count\u0026#34;, \u0026#34;subFields\u0026#34;: [] }, \u0026#34;as\u0026#34;: null } ], \u0026#34;from\u0026#34;: [ { \u0026#34;db\u0026#34;: null, \u0026#34;table\u0026#34;: \u0026#34;employees\u0026#34;, \u0026#34;as\u0026#34;: \u0026#34;e\u0026#34;, \u0026#34;operator\u0026#34;: null }, { \u0026#34;db\u0026#34;: null, \u0026#34;table\u0026#34;: \u0026#34;DepartmentSummary\u0026#34;, \u0026#34;as\u0026#34;: \u0026#34;d\u0026#34;, \u0026#34;join\u0026#34;: \u0026#34;JOIN\u0026#34;, \u0026#34;on\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;binary_expr\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;=\u0026#34;, \u0026#34;left\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;e\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;department_id\u0026#34;, \u0026#34;subFields\u0026#34;: [] }, \u0026#34;right\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;d\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;department_id\u0026#34;, \u0026#34;subFields\u0026#34;: [] } } }, { \u0026#34;db\u0026#34;: null, \u0026#34;table\u0026#34;: \u0026#34;employee_projects\u0026#34;, \u0026#34;as\u0026#34;: \u0026#34;ep\u0026#34;, \u0026#34;join\u0026#34;: \u0026#34;LEFT JOIN\u0026#34;, \u0026#34;on\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;binary_expr\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;=\u0026#34;, \u0026#34;left\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;e\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;employee_id\u0026#34;, \u0026#34;subFields\u0026#34;: [] }, \u0026#34;right\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;ep\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;employee_id\u0026#34;, \u0026#34;subFields\u0026#34;: [] } } }, { \u0026#34;db\u0026#34;: null, \u0026#34;table\u0026#34;: \u0026#34;ProjectSummary\u0026#34;, \u0026#34;as\u0026#34;: \u0026#34;p\u0026#34;, \u0026#34;join\u0026#34;: \u0026#34;LEFT JOIN\u0026#34;, \u0026#34;on\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;binary_expr\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;=\u0026#34;, \u0026#34;left\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;ep\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;project_id\u0026#34;, \u0026#34;subFields\u0026#34;: [] }, \u0026#34;right\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;p\u0026#34;, \u0026#34;column\u0026#34;: \u0026#34;project_id\u0026#34;, \u0026#34;subFields\u0026#34;: [] } } } ], \u0026#34;for_sys_time_as_of\u0026#34;: null, \u0026#34;where\u0026#34;: null, \u0026#34;with\u0026#34;: [ { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;DepartmentSummary\u0026#34; }, \u0026#34;stmt\u0026#34;: { \u0026#34;tableList\u0026#34;: [\u0026#34;select::null::departments\u0026#34;], \u0026#34;columnList\u0026#34;: [ \u0026#34;select::null::department_id\u0026#34;, \u0026#34;select::null::department_name\u0026#34; ], \u0026#34;ast\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;select\u0026#34;, \u0026#34;as_struct_val\u0026#34;: null, \u0026#34;distinct\u0026#34;: null, \u0026#34;columns\u0026#34;: [ { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;department_id\u0026#34; }, \u0026#34;as\u0026#34;: null }, { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;department_name\u0026#34; }, \u0026#34;as\u0026#34;: null }, { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;aggr_func\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;COUNT\u0026#34;, \u0026#34;args\u0026#34;: { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;star\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;*\u0026#34; } }, \u0026#34;over\u0026#34;: null }, \u0026#34;as\u0026#34;: \u0026#34;employee_count\u0026#34; } ], \u0026#34;from\u0026#34;: [ { \u0026#34;db\u0026#34;: null, \u0026#34;table\u0026#34;: \u0026#34;departments\u0026#34;, \u0026#34;as\u0026#34;: null, \u0026#34;operator\u0026#34;: null } ], \u0026#34;for_sys_time_as_of\u0026#34;: null, \u0026#34;where\u0026#34;: null, \u0026#34;with\u0026#34;: null, \u0026#34;groupby\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;department_id\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;department_name\u0026#34; } ], \u0026#34;having\u0026#34;: null, \u0026#34;qualify\u0026#34;: null, \u0026#34;orderby\u0026#34;: null, \u0026#34;limit\u0026#34;: null, \u0026#34;window\u0026#34;: null } } }, { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;ProjectSummary\u0026#34; }, \u0026#34;stmt\u0026#34;: { \u0026#34;tableList\u0026#34;: [\u0026#34;select::null::departments\u0026#34;, \u0026#34;select::null::projects\u0026#34;], \u0026#34;columnList\u0026#34;: [ \u0026#34;select::null::department_id\u0026#34;, \u0026#34;select::null::department_name\u0026#34;, \u0026#34;select::null::project_id\u0026#34;, \u0026#34;select::null::project_name\u0026#34; ], \u0026#34;ast\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;select\u0026#34;, \u0026#34;as_struct_val\u0026#34;: null, \u0026#34;distinct\u0026#34;: null, \u0026#34;columns\u0026#34;: [ { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;project_id\u0026#34; }, \u0026#34;as\u0026#34;: null }, { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;project_name\u0026#34; }, \u0026#34;as\u0026#34;: null }, { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;aggr_func\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;COUNT\u0026#34;, \u0026#34;args\u0026#34;: { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;star\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;*\u0026#34; } }, \u0026#34;over\u0026#34;: null }, \u0026#34;as\u0026#34;: \u0026#34;member_count\u0026#34; } ], \u0026#34;from\u0026#34;: [ { \u0026#34;db\u0026#34;: null, \u0026#34;table\u0026#34;: \u0026#34;projects\u0026#34;, \u0026#34;as\u0026#34;: null, \u0026#34;operator\u0026#34;: null } ], \u0026#34;for_sys_time_as_of\u0026#34;: null, \u0026#34;where\u0026#34;: null, \u0026#34;with\u0026#34;: null, \u0026#34;groupby\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;project_id\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;project_name\u0026#34; } ], \u0026#34;having\u0026#34;: null, \u0026#34;qualify\u0026#34;: null, \u0026#34;orderby\u0026#34;: null, \u0026#34;limit\u0026#34;: null, \u0026#34;window\u0026#34;: null } } } ], \u0026#34;groupby\u0026#34;: null, \u0026#34;having\u0026#34;: null, \u0026#34;qualify\u0026#34;: null, \u0026#34;orderby\u0026#34;: null, \u0026#34;limit\u0026#34;: null, \u0026#34;window\u0026#34;: null, \u0026#34;_orderby\u0026#34;: null, \u0026#34;_limit\u0026#34;: null } ] node-sql-parser を使っていた時に発生していた既知の不具合は コチラ にストックしてある。\n現時点で判明している不具合の多くは node-sql-parser が使用しているパーサーの改修が必要そうな雰囲気（要検証）。その場合、 node-sql-parser は内部で PEG.js というパーサージェネレータを使用しており、おそらく下記の部分を回収することになるのではないかと思われる（が、今回は一旦ここまでで…）。\n該当コード: https://github.com/taozhi8833998/node-sql-parser/blob/master/pegjs/bigquery.pegjs\n「PEG.js is 何？」は次の記事が参考になった。\nhttps://qiita.com/kujirahand/items/eab914bc77cf1bc0837c\n可視化方法の検討 先の記事 では Graphviz を用いて可視化していた。当初、 Graphviz が JavaScript でも使えることを知らずに別のライブラリでの実装を試みていた。そのときのメモを下記に示す（現在は Graphviz を用いている）。\nD3.js 当初、 D3.js での可視化を試みていた。理由は D3.js の hierarchy が今回の用途に使えそうだったから（後に使えないことが分かったが…）。\nhierarchy の実装については次の記事が参考になった。\nhttps://zenn.dev/yuji/articles/7eb96460317222\n前述の「使えないことが分かった」についてだが、「同名の子ノードが複数存在できてしまう」ことが問題となった。\n例えば、次のような SQL クエリがあったとする。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 WITH cte1 AS ( SELECT * FROM source1 ), cte2 AS ( SELECT * FROM source1 ), cte3 AS ( SELECT * FROM cte2 ) SELECT * FROM cte3 JOIN cte1 その場合…\n正規表現による可視化（本来） hierarchy による可視化 このように可視化してほしい。 しかし、 hierarchy だと次のような可視化になってしまう。 見てみると、 source1 が複数に分かれてしまっていることがわかる、おそらく子ノードが結合するような構造に hierarchy を適用するのは適切ではなかったものと思われる…（公式ドキュメント等を調べても、子ノードが結合するような構造に適用したサンプルは見つけられなかった）。\nなお、D3.js 以外では Mermaid.js も検討したが、公式の Live Editor のようにユーザ入力に応じで図を更新する方法が分からず沼ったので断念した。\nGraphviz 先の記事 と同じく Graphviz が JavaScript でも使えることが分かったので、最終的にこちらを採用した。\nGraphviz の操作は次の記事が参考になった。\nhttps://qiita.com/mmmmk/items/f7c70024938b0e38e4c9\nnode-sql-parser を使っていたときの実装 node-sql-parser を使っていたときの CTE 可視化の実装を下記に示す。\nnode-sql-parser や hierarchy の実装についてはほぼ公式ドキュメントや参考記事の通り。\n独自で実装したのは node-sql-parser で得られた構文木を hierarchy で可視化できるよう変換する処理。\nnode-sql-parser から得られる構文木のフォーマットは次のとおり。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 [ { \u0026#34;type\u0026#34;: \u0026#34;select\u0026#34;, ... \u0026#34;from\u0026#34;: [ { ... \u0026#34;table\u0026#34;: \u0026#34;\u0026lt;ROOT_FROM_TABLE\u0026gt;\u0026#34;, ... }, ... ], ... \u0026#34;with\u0026#34;: [ { \u0026#34;name\u0026#34;: { ... \u0026#34;value\u0026#34;: \u0026#34;\u0026lt;CTE_1\u0026#34; }, \u0026#34;stmt\u0026#34;: { ... \u0026#34;ast\u0026#34;: { ... \u0026#34;from\u0026#34;: [ { ... \u0026#34;table\u0026#34;: \u0026#34;CTE_1_FROM_TABLE\u0026gt;\u0026#34;, ... }, ... ], ... } } }, ... ], ... } ] hierarchy のフォーマットは次のとおり。\n1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;name\u0026#34;: \u0026#34;\u0026lt;ROOT\u0026gt;\u0026#34;, \u0026#34;children\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;\u0026lt;CHILDREN_1_DEPTH_1\u0026gt;\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;\u0026lt;CHILDREN_2_DEPTH_1\u0026gt;\u0026#34;, \u0026#34;children\u0026#34;: [ ... } 変換処理は主に次のステップで行うようにした。\n構文木のデータから CTE 同士の依存関係データを作成する 最後の SELECT ~ FROM で FROM している CTE に先の依存関係データを結合する 1 つ目のステップの実装コードは次のとおりである（ originalJson に構文木のデータが格納されている）。ポイントは、 CTE が CTE を FROM しているケースにも対応できるよう、再帰的に依存関係を特定している点である。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 let cteMap = new Map(); // \u0026#39;with\u0026#39;節の処理（もし存在する場合） if (originalJson[0].with) { originalJson[0].with.forEach((cte) =\u0026gt; { cteMap.set(cte.name.value, { name: cte.name.value, children: [], processed: false, }); }); // 再帰的にCTEの依存関係を解析 function processCte(cteName) { let cte = cteMap.get(cteName); if (cte.processed) { return cte; } cte.processed = true; originalJson[0].with.forEach((w) =\u0026gt; { if (w.name.value === cteName) { if (w.stmt.ast.from) { // CTE に FROM 句がない場合もあるため分岐を入れている w.stmt.ast.from.forEach((fromTable) =\u0026gt; { if (cteMap.has(fromTable.table)) { // FROM 句のテーブルがCTEの場合は深掘り cte.children.push(processCte(fromTable.table)); } else { // 依存の終端に達した場合はテーブル名を追加 cte.children.push({ name: fromTable.table, }); } }); } } }); return cte; } cteMap.forEach((_, cteName) =\u0026gt; processCte(cteName)); } 2 つ目のステップの実装コードは次のとおり。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 新しいJSONオブジェクトの初期化 let convertedJson = { name: \u0026#34;root\u0026#34;, children: [], }; // 各テーブルを処理 originalJson[0].from.forEach((table) =\u0026gt; { if (cteMap.has(table.table)) { convertedJson.children.push(cteMap.get(table.table)); } else { convertedJson.children.push({ name: table.table, }); } }); 各ステップの動作例を以下に記す。\n例えば、次のような SQL があったとする。\n1 2 3 4 5 6 7 8 9 10 11 WITH cte_depth_2 AS ( SELECT * FROM source ), cte_depth_1 AS ( SELECT * FROM cte_depth_2 ) SELECT * FROM cte_depth_1 この SQL から得られる構文木は次のようになる。\n長いので折りたたみ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 { \u0026#34;type\u0026#34;: \u0026#34;select\u0026#34;, \u0026#34;as_struct_val\u0026#34;: null, \u0026#34;distinct\u0026#34;: null, \u0026#34;columns\u0026#34;: [ { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;*\u0026#34; }, \u0026#34;as\u0026#34;: null } ], \u0026#34;from\u0026#34;: [ { \u0026#34;db\u0026#34;: null, \u0026#34;table\u0026#34;: \u0026#34;cte_depth_1\u0026#34;, \u0026#34;as\u0026#34;: null, \u0026#34;operator\u0026#34;: null } ], \u0026#34;for_sys_time_as_of\u0026#34;: null, \u0026#34;where\u0026#34;: null, \u0026#34;with\u0026#34;: [ { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;cte_depth_2\u0026#34; }, \u0026#34;stmt\u0026#34;: { \u0026#34;tableList\u0026#34;: [\u0026#34;select::null::source\u0026#34;], \u0026#34;columnList\u0026#34;: [\u0026#34;select::null::(.*)\u0026#34;], \u0026#34;ast\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;select\u0026#34;, \u0026#34;as_struct_val\u0026#34;: null, \u0026#34;distinct\u0026#34;: null, \u0026#34;columns\u0026#34;: [ { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;*\u0026#34; }, \u0026#34;as\u0026#34;: null } ], \u0026#34;from\u0026#34;: [ { \u0026#34;db\u0026#34;: null, \u0026#34;table\u0026#34;: \u0026#34;source\u0026#34;, \u0026#34;as\u0026#34;: null, \u0026#34;operator\u0026#34;: null } ], \u0026#34;for_sys_time_as_of\u0026#34;: null, \u0026#34;where\u0026#34;: null, \u0026#34;with\u0026#34;: null, \u0026#34;groupby\u0026#34;: null, \u0026#34;having\u0026#34;: null, \u0026#34;qualify\u0026#34;: null, \u0026#34;orderby\u0026#34;: null, \u0026#34;limit\u0026#34;: null, \u0026#34;window\u0026#34;: null } } }, { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;cte_depth_1\u0026#34; }, \u0026#34;stmt\u0026#34;: { \u0026#34;tableList\u0026#34;: [\u0026#34;select::null::source\u0026#34;, \u0026#34;select::null::cte_depth_2\u0026#34;], \u0026#34;columnList\u0026#34;: [\u0026#34;select::null::(.*)\u0026#34;], \u0026#34;ast\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;select\u0026#34;, \u0026#34;as_struct_val\u0026#34;: null, \u0026#34;distinct\u0026#34;: null, \u0026#34;columns\u0026#34;: [ { \u0026#34;expr\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;column_ref\u0026#34;, \u0026#34;table\u0026#34;: null, \u0026#34;column\u0026#34;: \u0026#34;*\u0026#34; }, \u0026#34;as\u0026#34;: null } ], \u0026#34;from\u0026#34;: [ { \u0026#34;db\u0026#34;: null, \u0026#34;table\u0026#34;: \u0026#34;cte_depth_2\u0026#34;, \u0026#34;as\u0026#34;: null, \u0026#34;operator\u0026#34;: null } ], \u0026#34;for_sys_time_as_of\u0026#34;: null, \u0026#34;where\u0026#34;: null, \u0026#34;with\u0026#34;: null, \u0026#34;groupby\u0026#34;: null, \u0026#34;having\u0026#34;: null, \u0026#34;qualify\u0026#34;: null, \u0026#34;orderby\u0026#34;: null, \u0026#34;limit\u0026#34;: null, \u0026#34;window\u0026#34;: null } } } ], \u0026#34;groupby\u0026#34;: null, \u0026#34;having\u0026#34;: null, \u0026#34;qualify\u0026#34;: null, \u0026#34;orderby\u0026#34;: null, \u0026#34;limit\u0026#34;: null, \u0026#34;window\u0026#34;: null, \u0026#34;_orderby\u0026#34;: null, \u0026#34;_limit\u0026#34;: null } 1 つ目のステップでは、この構文木のデータから次のような依存関係データを作成する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 [ [ \u0026#34;cte_depth_2\u0026#34;, { \u0026#34;name\u0026#34;: \u0026#34;cte_depth_2\u0026#34;, \u0026#34;children\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;source\u0026#34; } ], \u0026#34;processed\u0026#34;: true } ], [ \u0026#34;cte_depth_1\u0026#34;, { \u0026#34;name\u0026#34;: \u0026#34;cte_depth_1\u0026#34;, \u0026#34;children\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;cte_depth_2\u0026#34;, \u0026#34;children\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;source\u0026#34; } ], \u0026#34;processed\u0026#34;: true } ], \u0026#34;processed\u0026#34;: true } ] ] 2 つ目のステップを経て、最終的に次のような hierarchy 用データになる。今回のクエリでは、最終クエリは cte_depth_1 を FROM していたので、1 つ目のステップで得られた cte_depth_1 の依存関係データを結合すれば OK となる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \u0026#34;name\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;children\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;cte_depth_1\u0026#34;, \u0026#34;children\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;cte_depth_2\u0026#34;, \u0026#34;children\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;source\u0026#34; } ], \u0026#34;processed\u0026#34;: true } ], \u0026#34;processed\u0026#34;: true } ] } ","date":"2024-02-25T11:53:00Z","permalink":"https://yamamoto-yuta.github.io/p/visualizing-cte-dependencies-in-javascript/","title":"SQL の CTE の依存関係を JavaScript で可視化してみる"},{"content":" ✏️ 編集\nSlack の Slash Commands を作成した際に色々つまづいたのでメモに残す。\n今回のゴール /echo で echo と返すスラッシュコマンドを作成する /hoge で hoge と返すスラッシュコマンドを作成する ngrok のセットアップ ダウンロードページの URL : https://ngrok.com/download\nアカウントを作成せずに利用していたが、次のエラーが出たのでアカウントを作成した:\n1 2 3 4 ERR_NGROK_6022 Before you can serve HTML content, you must sign up for an ngrok account and install your authtoken. https://ngrok.com/docs/errors/err_ngrok_6022/ 次のコマンドで ngrok を起動させる（今回は 3000 番ポートを使うことにする）:\n1 $ ngrok http 3000 各種ファイルの作成 .env.sample :\n1 2 3 4 WORKING_DIR=/usr/src/app OPENAI_API_KEY=# Your OpenAI API key SLACK_BOT_TOKEN=# OAuth \u0026amp; Permissions \u0026gt; OAuth Tokens for Your Workspace \u0026gt; Bot User OAuth Access Token SLACK_SIGNING_SECRET=# Basic Information \u0026gt; App Credentials \u0026gt; Signing Secret Dockerfile :\n1 2 3 4 5 6 7 8 FROM python:3.10 COPY requirements.txt ${WORKING_DIR}/ RUN apt-get update \u0026amp;\u0026amp; apt-get upgrade -y RUN pip install --upgrade pip \u0026amp;\u0026amp; \\ pip install -r requirements.txt docker-compose.yml :\n1 2 3 4 5 6 7 8 9 10 11 12 13 version: \u0026#34;3.7\u0026#34; services: app: build: . env_file: - .env volumes: - .:$WORKING_DIR working_dir: $WORKING_DIR tty: true ports: - 3000:3000 requirements.txt :\n1 slack_bolt==1.18.1 main.py :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import os from slack_bolt import App app = App( signing_secret=os.environ[\u0026#34;SLACK_SIGNING_SECRET\u0026#34;], token=os.environ[\u0026#34;SLACK_BOT_TOKEN\u0026#34;] ) @app.command(\u0026#34;/echo\u0026#34;) def echo(ack, respond): ack() respond(\u0026#34;echo\u0026#34;) @app.command(\u0026#34;/hoge\u0026#34;) def hoge(ack, respond): ack() respond(\u0026#34;hoge\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: app.start(port=3000) 実行コマンドは次のとおり:\n1 2 3 4 $ docker-compose build $ docker-compose up -d $ docker exec -it \u0026lt;CONTAINER_ID\u0026gt; bash [IN CONTAINER]# python main.py Slack App 設定 App 作成 まずは普通に Slack App を作成。 App Display Name 、 Default username がデフォルトだと空欄になっており、これらを設定しないとワークスペースへインストールできないので、忘れず設定すること。\n参考:\n【Slack】インストールするボットユーザーがありませんと出たときの対処方法 | THE SIMPLE Slash Commands 1 2 3 4 5 6 7 8 9 slash_commands: - command: /echo url: https://xxxxxxxxxx.ngrok-free.app/slack/events description: echo should_escape: false - command: /hoge url: https://xxxxxxxxxx.ngrok-free.app/slack/events description: hoge should_escape: false ⚠️ url のエンドポイントは /echo や /hoge ではなく一律 /slack/events （ここで無駄に時間を溶かしてしまった…）\n参考: コマンドのリスニングと応答 - Slack | Bolt for Python\nOAuth \u0026amp; Permissions 実際に動かしてみる 入力 実行結果 ","date":"2023-11-25T17:45:00Z","permalink":"https://yamamoto-yuta.github.io/p/slack-slash-commands-notes/","title":"Slack の Slash Commands 作成メモ"},{"content":" ✏️ 編集\nFunction Calling が説明等を読んでもイマイチよくわからなかったので実際に試してみた。これはその時のメモ。\n今回は次の公式ドキュメントの手順をやってみた。\nhttps://platform.openai.com/docs/guides/function-calling\nまた、次の日本語解説記事が参考になった。\nhttps://dev.classmethod.jp/articles/understand-openai-function-calling/\nセットアップ 今回、実行環境は Google Colab にした。\nまずは OpenAI ライブラリをインストール。\n1 !pip install openai 続いて、各種ライブラリのインポートと OpenAI クライアントを作成。\n1 2 3 4 5 6 import json from openai import OpenAI client = OpenAI( api_key=OPENAI_API_KEY ) OpenAI API Key は次のページで作成できる:\nAPI keys - OpenAI API\n今回、 Function Calling の動作確認用に次のダミー関数を利用した。\n1 2 3 4 5 6 7 8 9 10 11 12 # Example dummy function hard coded to return the same weather # In production, this could be your backend API or an external API def get_current_weather(location, unit=\u0026#34;fahrenheit\u0026#34;): \u0026#34;\u0026#34;\u0026#34;Get the current weather in a given location\u0026#34;\u0026#34;\u0026#34; if \u0026#34;tokyo\u0026#34; in location.lower(): return json.dumps({\u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}) elif \u0026#34;san francisco\u0026#34; in location.lower(): return json.dumps({\u0026#34;location\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;72\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;fahrenheit\u0026#34;}) elif \u0026#34;paris\u0026#34; in location.lower(): return json.dumps({\u0026#34;location\u0026#34;: \u0026#34;Paris\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}) else: return json.dumps({\u0026#34;location\u0026#34;: location, \u0026#34;temperature\u0026#34;: \u0026#34;unknown\u0026#34;}) 全体像 公式ドキュメントのコードの全体像は次のとおり:\n（AI が）質問に必要な関数を選び、引数を作成する （プログラムが）関数を実行 （AI が）関数結果も入力に入れて質問に回答する 引用: [OpenAI] Function calling で遊んでみたら本質が見えてきたのでまとめてみた | DevelopersIO\nSTEP 1 ｜会話と利用可能な関数をモデルに送る 公式ドキュメントのコード（日本語のコメントは自分で追記した）:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # Step 1: send the conversation and available functions to the model # 会話 messages = [{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What\u0026#39;s the weather like in San Francisco, Tokyo, and Paris?\u0026#34;}] # 利用可能な関数 tools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the current weather in a given location\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;unit\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;celsius\u0026#34;, \u0026#34;fahrenheit\u0026#34;]}, }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;], }, }, } ] # モデルへ投げて回答を取得 response = client.chat.completions.create( model=\u0026#34;gpt-3.5-turbo-1106\u0026#34;, messages=messages, tools=tools, tool_choice=\u0026#34;auto\u0026#34;, # auto is default, but we\u0026#39;ll be explicit ) response の中身はこんな感じ。今回はサンフランシスコ、東京、パリの 3 つの都市の天気を訊いているので、 tool_calls が 3 リクエスト分になっている。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 { \u0026#39;id\u0026#39;: \u0026#39;chatcmpl-xxxxxxxxxx\u0026#39;, \u0026#39;choices\u0026#39;: [ Choice( finish_reason=\u0026#39;tool_calls\u0026#39;, index=0, message=ChatCompletionMessage( content=None, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[ ChatCompletionMessageToolCall( id=\u0026#39;call_aaaaaaaaaa\u0026#39;, function=Function( arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39; ), type=\u0026#39;function\u0026#39; ), ChatCompletionMessageToolCall( id=\u0026#39;call_bbbbbbbbbb\u0026#39;, function=Function( arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39; ), type=\u0026#39;function\u0026#39; ), ChatCompletionMessageToolCall( id=\u0026#39;call_cccccccccc\u0026#39;, function=Function( arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Paris\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39; ), type=\u0026#39;function\u0026#39; ) ] ) ) ], \u0026#39;created\u0026#39;: 1700895213, \u0026#39;model\u0026#39;: \u0026#39;gpt-3.5-turbo-1106\u0026#39;, \u0026#39;object\u0026#39;: \u0026#39;chat.completion\u0026#39;, \u0026#39;system_fingerprint\u0026#39;: \u0026#39;fp_xxxxxxxxxx\u0026#39;, \u0026#39;usage\u0026#39;: CompletionUsage( completion_tokens=77, prompt_tokens=88, total_tokens=165 ) } この中から次の 2 つを取り出す。\n1 2 response_message = response.choices[0].message tool_calls = response_message.tool_calls 次の処理に入る前に、 Function Calling が要求されているかのチェックが必要。\n1 2 3 # Step 2: check if the model wanted to call a function if tool_calls: ... STEP 2 ｜実際に関数を実行する 公式ドキュメント:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Step 3: call the function # Note: the JSON response may not always be valid; be sure to handle errors available_functions = { \u0026#34;get_current_weather\u0026#34;: get_current_weather, } # only one function in this example, but you can have multiple messages.append(response_message) # extend conversation with assistant\u0026#39;s reply # Step 4: send the info for each function call and function response to the model for tool_call in tool_calls: function_name = tool_call.function.name function_to_call = available_functions[function_name] function_args = json.loads(tool_call.function.arguments) function_response = function_to_call( location=function_args.get(\u0026#34;location\u0026#34;), unit=function_args.get(\u0026#34;unit\u0026#34;), ) messages.append( { \u0026#34;tool_call_id\u0026#34;: tool_call.id, \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;name\u0026#34;: function_name, \u0026#34;content\u0026#34;: function_response, } ) # extend conversation with function response 分解して見ていく。\n利用可能な関数の辞書を作成している。今回は get_current_weather() しか利用できないので、辞書内のアイテムは 1 つだけになる。\n1 2 3 available_functions = { \u0026#34;get_current_weather\u0026#34;: get_current_weather, } # only one function in this example, but you can have multiple available_functions の中身は次のようになっている。関数がオブジェクトとして辞書に登録されている。\n1 {\u0026#39;get_current_weather\u0026#39;: \u0026lt;function __main__.get_current_weather(location, unit=\u0026#39;fahrenheit\u0026#39;)\u0026gt;} STEP 1 で得た response_message を message に append している。これは STEP 3 で最終的な回答を作成するために使用する。\n1 messages.append(response_message) # extend conversation with assistant\u0026#39;s reply したがって、 messages の中身は次のようになる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 [ { \u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#34;What\u0026#39;s the weather like in San Francisco, Tokyo, and Paris?\u0026#34; }, ChatCompletionMessage( content=None, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[ ChatCompletionMessageToolCall( id=\u0026#39;call_aaaaaaaaaa\u0026#39;, function=Function( arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39; ), type=\u0026#39;function\u0026#39; ), ChatCompletionMessageToolCall( id=\u0026#39;call_bbbbbbbbbb\u0026#39;, function=Function( arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39; ), type=\u0026#39;function\u0026#39; ), ChatCompletionMessageToolCall( id=\u0026#39;call_cccccccccc\u0026#39;, function=Function( arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Paris\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39; ), type=\u0026#39;function\u0026#39; ) ] ) ] STEP 1 で作成したリクエストをループで順次、実際に関数へリクエストしていく。\n1 2 3 # Step 4: send the info for each function call and function response to the model for tool_call in tool_calls: ... 実際に関数を実行する部分は次のコード。\n1 2 3 4 5 6 7 8 9 10 11 12 # 呼び出す関数を取得 function_name = tool_call.function.name function_to_call = available_functions[function_name] # 関数に渡す引数を取得（引数は JSON 文字列で格納されているので json.loads() ） function_args = json.loads(tool_call.function.arguments) # 実際に関数を実行する function_response = function_to_call( location=function_args.get(\u0026#34;location\u0026#34;), unit=function_args.get(\u0026#34;unit\u0026#34;), ) 関数の実行結果を messages へ append している。これは STEP 3 で最終的な回答を作成するためである。\n1 2 3 4 5 6 7 8 messages.append( { \u0026#34;tool_call_id\u0026#34;: tool_call.id, \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;name\u0026#34;: function_name, \u0026#34;content\u0026#34;: function_response, } ) # extend conversation with function response ループ終了時の messages の中身は次のようになっている。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [{\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#34;What\u0026#39;s the weather like in San Francisco, Tokyo, and Paris?\u0026#34;}, ChatCompletionMessage(content=None, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=\u0026#39;call_aaaaaaaaaa\u0026#39;, function=Function(arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39;), type=\u0026#39;function\u0026#39;), ChatCompletionMessageToolCall(id=\u0026#39;call_bbbbbbbbbb\u0026#39;, function=Function(arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39;), type=\u0026#39;function\u0026#39;), ChatCompletionMessageToolCall(id=\u0026#39;call_cccccccccc\u0026#39;, function=Function(arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Paris\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39;), type=\u0026#39;function\u0026#39;)]), {\u0026#39;tool_call_id\u0026#39;: \u0026#39;call_aaaaaaaaaa\u0026#39;, \u0026#39;role\u0026#39;: \u0026#39;tool\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;get_current_weather\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;72\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;fahrenheit\u0026#34;}\u0026#39;}, {\u0026#39;tool_call_id\u0026#39;: \u0026#39;call_bbbbbbbbbb\u0026#39;, \u0026#39;role\u0026#39;: \u0026#39;tool\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;get_current_weather\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;}, {\u0026#39;tool_call_id\u0026#39;: \u0026#39;call_cccccccccc\u0026#39;, \u0026#39;role\u0026#39;: \u0026#39;tool\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;get_current_weather\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Paris\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;}] STEP 3 ｜最終的な回答を作成する 公式ドキュメントのコード:\n1 2 3 4 second_response = client.chat.completions.create( model=\u0026#34;gpt-3.5-turbo-1106\u0026#34;, messages=messages, ) # get a new response from the model where it can see the function response second_response の中身:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \u0026#39;id\u0026#39;: \u0026#39;chatcmpl-yyyyyyyyyy\u0026#39;, \u0026#39;choices\u0026#39;: [ Choice( finish_reason=\u0026#39;stop\u0026#39;, index=0, message=ChatCompletionMessage( content=\u0026#39;Currently, the weather in San Francisco is 72°F, in Tokyo it is 10°C, and in Paris it is 22°C.\u0026#39;, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=None ) ) ], \u0026#39;created\u0026#39;: 1700895214, \u0026#39;model\u0026#39;: \u0026#39;gpt-3.5-turbo-1106\u0026#39;, \u0026#39;object\u0026#39;: \u0026#39;chat.completion\u0026#39;, \u0026#39;system_fingerprint\u0026#39;: \u0026#39;fp_eeff13170a\u0026#39;, \u0026#39;usage\u0026#39;: CompletionUsage( completion_tokens=29, prompt_tokens=169, total_tokens=198 ) } second_response.choices[0].message.content を見てみると、関数の実行結果が回答に組み込まれていることがわかる。\n1 \u0026#39;Currently, the weather in San Francisco is 72°F, in Tokyo it is 10°C, and in Paris it is 22°C.\u0026#39; 何が嬉しいのか？ （ほぼほぼ「 [OpenAI] Function calling で遊んでみたら本質が見えてきたのでまとめてみた | DevelopersIO 」に書かれていることではあるが…）\n例えば、今回のように自然言語で各都市の気温を問い合わせる仕組みを作る場合、 ChatGPT だけでは各都市の気温は答えられないので API 等で別途情報を取得してくる必要がある（補足）。そのため、問い合わせ文から API 等へのリクエストに必要な情報を抽出する必要があった。\n「 What\u0026rsquo;s the weather like in San Francisco, Tokyo, and Paris? 」という質問の場合、（どのような情報がリクエストに必要かによるが）「 San Francisco 」「 Tokyo 」「 Paris 」の 3 つの情報を抽出する必要がある。\nFunction Calling が登場するまでは、プロンプトを工夫することで情報を抽出しやすくしていた。\n例えば次のプロンプトを用いたとする。\n1 2 3 4 5 6 7 8 次の問い合わせ文から都市を抽出してください。出力フォーマットは次のようにしてください: ## 出力フォーマット - 都市1 - 都市2 ## 問い合わせ文 What\u0026#39;s the weather like in San Francisco, Tokyo, and Paris? すると、 ChatGPT は次のように回答してくれる。\n1 2 3 4 ## 出力フォーマット - San Francisco - Tokyo - Paris 今回の気温の例は出力フォーマットがシンプルだったので比較的指定したフォーマットで回答してくれているが、複雑な出力フォーマットだったりすると指定したフォーマットにしたがってくれなかったりする。\nFunction Calling を使えば、引数の仕様を指定すればそれに合うように情報を抽出してくれる。例えば今回の場合、次のように情報を抽出してくれていた。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [ ChatCompletionMessageToolCall( id=\u0026#39;call_aaaaaaaaaa\u0026#39;, function=Function( arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39; ), type=\u0026#39;function\u0026#39; ), ChatCompletionMessageToolCall( id=\u0026#39;call_bbbbbbbbbb\u0026#39;, function=Function( arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39; ), type=\u0026#39;function\u0026#39; ), ChatCompletionMessageToolCall( id=\u0026#39;call_cccccccccc\u0026#39;, function=Function( arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Paris\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;celsius\u0026#34;}\u0026#39;, name=\u0026#39;get_current_weather\u0026#39; ), type=\u0026#39;function\u0026#39; ) ] 補足: 今は Browse with Bing のおかげで ChatGPT 単体での回答が可能になっている 現在では ChatGPT に「 Browse with Bing 」機能が搭載されているため、 LLM 単体でも回答が可能となっている。\n例えば、今回の「 What\u0026rsquo;s the weather like in San Francisco, Tokyo, and Paris? 」という質問を ChatGPT (ChatGPT Plus 加入版) に投げてみたところ、次の回答が得られた:\n現在の天気について、以下の都市の情報は次の通りです：\nサンフランシスコ（カリフォルニア州、アメリカ）：気温は 57°F（約 14°C）で、部分的に雲があります。今後の予報では最高気温が 66°F（約 19°C）、最低気温が 49°F（約 9°C）となる見込みです。風速は北東から 5mph（約 8km/h）です[”]。\n東京（日本）：気温は 60°F（約 16°C）で、涼しいです。今後の予報では最高気温が 76°F（約 24°C）、最低気温が 48°F（約 9°C）となる見込みです。風速は南から 9mph（約 14km/h）です[”]。\nパリ（フランス）：気温は 41°F（約 5°C）で、一部に雲があります。体感温度は 39°F（約 4°C）です。今後の予報では最高気温が 56°F（約 13°C）、最低気温が 40°F（約 4°C）となる見込みです。風速は北西から 3mph（約 5km/h）です[”]。\nこれらの情報は、各都市の現在の気象条件を反映しています。天候は変わりやすいので、最新の情報を得るためには、定期的に天気予報を確認することをお勧めします。\n","date":"2023-11-25T11:54:00Z","permalink":"https://yamamoto-yuta.github.io/p/function-calling-memo/","title":"Function Calling 触ってみたメモ"},{"content":" ✏️ 編集\n先日、ブラウザ拡張機能「 CSV2MD Shortcut 」の v0.2.0 をリリースした 。このバージョンでは新機能として Popup からテキスト変換を行えるようにした。 v0.1.0 では BSW にテキスト変換処理を実装していた。 Popup からテキスト変換を行えるようにするにあたってその処理を BSW から切り出そうとした。が、うまくいかなかった…。 この記事では、そのときの試行錯誤をログとして残す。 該当 issue:\nhttps://github.com/yamamoto-yuta/csv2md-shortcut/issues/35\n検証用リポジトリ:\nhttps://github.com/yamamoto-yuta/chrome-extension-injected-code-debug\n公式ドキュメントの記載:\nFor the func key, you can pass in a TS function from your project. It will be transpiled into JS when your extension bundles. You may also use the files key to inject a file from the root of the built bundle.\nこれを読む限り、ビルド済みファイルに手を加えるしか無さそう…？（であれば、それは管理面倒くさくなりそうなのでやらない方が良さそう…）\n","date":"2023-08-05T15:57:00Z","permalink":"https://yamamoto-yuta.github.io/p/executing-functions-from-other-files-in-executescript/","title":"executeScript() で呼ぶ関数の中で別ファイルの関数を呼び出したい"},{"content":" ✏️ 編集\n2024/06/30 に v1.0.0 がリリースされたので、以後は README の手順で OK。\nhttps://github.com/ShotaroKataoka/ls-Improved\n2024/06/29以前の方法 コードはここ https://github.com/ShotaroKataoka/ls-Improved/tree/develop-rust-rewrite\nManual 公式 GitHub の Releases ページからダウンロード ダウンロードファイルを解凍して、lsi を使いたいディレクトリへ移動 path/to/lsi-** で動く 毎回 path/to/lsi-** と打つのは面倒くさいので alias を登録しておくと良い。\napt 手順 PPA リポジトリ:\nhttps://github.com/ShotaroKataoka/ppa\nGPG 鍵をダウンロード 1 curl -s --compressed \u0026#34;https://ShotaroKataoka.github.io/ppa/ubuntu/KEY.gpg\u0026#34; | gpg --dearmor | tee /etc/apt/trusted.gpg.d/ls_improved_ppa.gpg PPA を追加 1 echo \u0026#34;deb [signed-by=/etc/apt/trusted.gpg.d/ls_improved_ppa.gpg] https://ShotaroKataoka.github.io/ppa/ubuntu ./\u0026#34; | tee /etc/apt/sources.list.d/ls_Improved.list インストール 1 apt-get update \u0026amp;\u0026amp; apt-get install ls-improved 検証用環境 Dockerfile:\n1 2 3 4 5 FROM ubuntu:20.04 RUN apt-get update \u0026amp;\u0026amp; apt-get upgrade -y \u0026amp;\u0026amp; apt-get install -y \\ curl \\ gpg docker-compose.yml\n1 2 3 4 5 6 7 version: \u0026#34;3.8\u0026#34; services: ubuntu: build: . image: ubuntu-apt-install-sandbox container_name: ubuntu tty: true 参考記事 .deb ファイルをカスタマイズして、GitHub で PPA をホストして、Debian にインストールする方法（その 4: ホスティングした PPA から、パッケージを Debian にインストールする）｜ Ryo Nakano gcloud CLI をインストールする | Google Cloud ","date":"2023-07-23T14:50:00Z","permalink":"https://yamamoto-yuta.github.io/p/rust-ls-improved-installation-notes/","title":"Rust 版 ls-Improved 導入メモ"},{"content":" ✏️ 編集\n前から気になっていたブラウザ拡張機能の開発フレームワーク「Plasmo」を触ってみたので、その時のメモ。\n基本的に下記の記事をなぞる形で触っていった。\nブラウザ拡張機能を作るための React フレームワーク『Plasmo』\nなので、ここでは上記記事をなぞった際につまづいた箇所や個人的な所感などについて記す。\n環境構築を Docker でやってみた ローカル環境がごちゃごちゃするのが個人的に嫌だったので、 Docker で環境構築してみた。\n上記記事や公式ドキュメントには特に Docker についての言及は無かったが、 Node.js があれば十分だったので適当な Node.js のイメージを持ってこればいけるはず。\nちなみに、 Plasmo のシステム要件として Node.js が 16.14 以降であることが挙げられていた。\nNode.js 16.14.x or later\n引用: https://docs.plasmo.com/framework#system-requirements\nただ、 Node.js のリリースケジュールによると 16 系は今年（記事執筆時は 2023 年 6 月 4 日）の 9 月で End-of-life とのことだったので、今回は 18 系を使ってみることにした。\nNode.js のリリーススケジュール:\nhttps://github.com/nodejs/Release#release-schedule\n以上を踏まえて作成した docker-compose.yml が下記の通り:\n1 2 3 4 5 6 7 8 9 version: \u0026#34;3\u0026#34; services: app: image: node:18.16.0 volumes: - .:/usr/src/app working_dir: /usr/src/app tty: true Plasmo プロジェクトの作成は docker compose run コマンドを用いて下記で行える。なお、 Plasmo は pnpm コマンドの利用を推奨していたが、 Node.js のイメージにデフォルトで入っていなかったので今回はデフォルトで入っている npm コマンドで進めた。コマンド実行のためにコンテナが溜まっていかないよう --rm オプションを付けている。\n1 $ docker compose run --rm app npm create plasmo プロジェクト作成の際に色々訊かれたが、今回は拡張機能の名前を learn-plasmo にした以外は既定値で回答した。\nDevelopment server の起動も同様に下記のコマンドで行える。プロジェクトディレクトリ（ learn-plasmo/ ）に移動する必要がある点に注意。\n1 $ docker compose run --rm app bash -c \u0026#34;cd learn-plasmo \u0026amp;\u0026amp; npm run dev\u0026#34; 記事中に Storage API を利用するためにパッケージを追加インストールするくだりがあるが、それも下記コマンドで行える:\n1 $ docker compose run --rm app bash -c \u0026#34;cd learn-plasmo \u0026amp;\u0026amp; npm install @plasmohq/storage react-hook-form\u0026#34; 他にも Messaging API を利用するためにも追加インストールのくだりがあったが、それも下記コマンドで行える:\n1 $ docker compose run --rm app bash -c \u0026#34;cd learn-plasmo \u0026amp;\u0026amp; npm install @plasmohq/messaging\u0026#34; つまづいた点メモ 「 Storage を利用する 」のところでなぜか入力値が保存されなくてつまづいたが、一度 Production build で動かした後 Development server に戻ってきたらちゃんと保存されるようになった。原因は不明…（要検証） 「 New Tab Page 」のところは自分が Vivaldi ユーザだったせいでそもそもカスタマイズできなかった ファイル変更時は「ホットリロードが走る → 拡張機能を再読み込み」の手順を踏むと反映される 個人的な所感 デフォルトで下記の機能が付いてるのが良かった:\ndev/prod のビルド分け ホットリロード また、今回は試さなかったが下記の機能も良さそうだった:\nChrome Web Store への自動デプロイ Google Analytics と連携できるっぽい（→ 公式ドキュメント ） メンテナンスもこまめにされてそうなので、これから拡張機能作るときは Plasmo 使うようにしてみようかな…\n","date":"2023-06-04T12:54:00Z","permalink":"https://yamamoto-yuta.github.io/p/memo-on-trying-plasmo/","title":"Plasmo 触ってみたメモ"},{"content":" ✏️ 編集\nいつも使ってる Slack 向け絵文字ジェネレーター:\n絵文字ジェネレーター - Slack 向け絵文字を無料で簡単生成\nリポジトリを見てみるとバックエンドに Python を用いており、その中で emojilib という自作ライブラリを用いていることが分かった。\nそこで emojilib のリポジトリを見てみると、 emojilib は libemoji という C/C++ 製の自作ライブラリの Python ラッパーということが分かった。\nemojilib を動かせるようにした Dockerfile を下記に示す。 emojilib 自体は pip install でインストールできるのだが、 libemoji を動かすため依存が いくつかあった ので別途 apt-get install で入れている。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 FROM python:3.7 RUN apt-get update \u0026amp;\u0026amp; apt-get upgrade -y RUN apt-get install -y \\ git \\ cmake \\ g++ \\ libfontconfig1-dev \\ libx11-dev \\ libxcomposite-dev \\ libgl1-mesa-dev \\ libglu1-mesa-dev \\ freeglut3-dev RUN pip install --upgrade pip RUN pip install emojilib --extra-index-url https://repo.fury.io/emoji-gen/ ","date":"2023-05-07T16:08:00Z","permalink":"https://yamamoto-yuta.github.io/p/how-slack-emoji-generator-works/","title":"いつも使ってるSlack向け絵文字ジェネレーターがどうやって絵文字を生成してるか調べてみたメモ"},{"content":" ✏️ 編集\nやりたいこと Slack API 経由で Slack へ絵文字を追加したい\n調べたこと 方針 1: Slack API の admin.emoji.add を利用する 公式で用意されている絵文字追加用 API。\n公式ドキュメント: https://api.slack.com/methods/admin.emoji.add\nただし、結局この API は使えなかった。理由はこの API を利用するには Slack App に admin.teams:write という権限を付与する必要があったから。\nadmin.teams:write についての公式ドキュメント: https://api.slack.com/scopes/admin.teams:write\nこれには次の問題があったので今回は方針を変更することにした:\nAdmin API は個々のワークスペースではなく組織全体に影響を与えることができ、ただ絵文字を追加するだけの用途で付与するには不適当なため そもそも Enterprise 版でないと利用できないため 方針 2: 一般公開されていない API /api/emoji.add を利用する どうやら Slack には一般公開されていない API がいくつかあるらしく、その中の一つである /api/emoji.add を利用すれば絵文字の追加が可能らしい:\n参考: https://github.com/slackhq/slack-api-docs/issues/28#issuecomment-424195796\nこの API を利用しているプロダクトがいくつかあるようだったので、それらを参考に API を叩いてみた。 API を叩く手順は次の通り。\n/api/emoji.add API を叩く手順 1. トークンを入手する 絵文字を追加したいワークスペースを開く 開発者ツールを開き、コンソールタブで次のコマンドを実行する 1 2 3 JSON.parse(localStorage.localConfig_v2).teams[ document.location.pathname.match(/^\\/client\\/(T[A-Z0-9]+)/)[1] ].token; 引用: https://github.com/jackellenberger/emojme/blob/master/README.md#cookie-token-one-liner\nxoxc-xxxxxxxxxx といった形式のトークンが返ってくるはず。\n2. Cookie を入手する https://\u0026lt;TEAM_ID\u0026gt;.slack.com/customize/emoji を開く（ワークスペースを開いた状態で「以下をカスタマイズ」をクリックすると飛べる） 開発者ツールを開き、「ネットワーク」タブを開く emoji というドキュメントを選択する リクエストヘッダーの cookie: の値が入手したい Cookie （この値をコピーするとき、「右クリック \u0026gt; 『値をコピー』」だとコピー後の文字列に日本語が混じって後で困るので、範囲選択でコピーする必要がある） 3. API を叩く API を叩くコード:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import requests TOKEN = \u0026#34;xoxc-xxxxxxxxxx\u0026#34; # トークン COOKIE = \u0026#34;xxxxxxxxxx\u0026#34; # Cookie team_name = \u0026#34;xxxxxxxxxx\u0026#34; # ワークスペースのチーム名 emoji_name = \u0026#34;emoji\u0026#34; # 絵文字の名前 emoji_img_filepath = \u0026#34;./emoji.png\u0026#34; # 絵文字の画像ファイルへのパス URL_ADD = \u0026#34;https://{team_name}.slack.com/api/emoji.add\u0026#34; r = requests.post( URL_ADD.format(team_name=team_name), headers = {\u0026#39;Cookie\u0026#39;: COOKIE}, data = { \u0026#39;mode\u0026#39;: \u0026#39;data\u0026#39;, \u0026#39;name\u0026#39;: emoji_name, \u0026#39;token\u0026#39;: TOKEN }, files={\u0026#39;image\u0026#39;: open(emoji_img_filepath, \u0026#39;rb\u0026#39;)} ) 次のレスポンスが返ってきていれば成功:\n1 {\u0026#34;ok\u0026#34;:true} 残る課題 トークンと Cookie の入手を自動でできないか？ 余談 /api/emoji.add の xoxb トークンでの利用について /api/emoji.add を xoxb トークンで利用できるよう求める Issue が 2019 年 1 月に建てられているが、2023 年 5 月現在、まだ Open なままである。\n該当 Issue: https://github.com/slackhq/slack-api-docs/issues/95\nxoxc トークンをスクレイピングで入手する https://\u0026lt;TEAM_ID\u0026gt;.slack.com/customize/emoji ページをスクレイピングすることで xoxc トークンを入手している例を紹介している 記事 を見つけた。\n該当コード: https://github.com/smashwilson/slack-emojinator/blob/fbcf759ebbda8bd37b77c91362edde9fd3e0c05a/upload.py#L81-L94\nしかし、やってみたがうまくいかなかった（ api_token: の値が \u0026quot;\u0026quot; だった）。やってみた当時はまだトークンや Cookie の入手などが手探りの状態だったので、それが原因でうまくいかなかったのかも…？\n参考 Slack で絵文字を追加するサービスを作ろうとしたときに調べたこと Slack Custom Emoji を追加する非公開 API /api/emoji.add | CodeNote smashwilson/slack-emojinator: Bulk upload emoji into Slack Fauntleroy/neutral-face-emoji-tools: Utilities that make life as a Slack emoji addict a little easier. jackellenberger/emojme: very powerful very stupid Slack emoji tools, holy cow! ","date":"2023-05-06T16:56:00Z","permalink":"https://yamamoto-yuta.github.io/p/api-add-custom-emoji-to-slack/","title":"API経由でSlackへカスタム絵文字を追加できないか調査したときのメモ"},{"content":" ✏️ 編集\n「Q-Q プロット」って何？ 2 つの確率分布の分位数を互いにプロットして，両者がどのくらい類似した確率分布なのかを可視化する手法．\n縦軸に調べたい確率分布の分位数，横軸に理論分布の確率密度関数の逆関数をプロットする．分布が類似していれば $y=x$ 的な直前上にプロットされる．\nQ-Q プロットの一例:\n引用: 【Python】正規分布に従っているかを調べる手法 3 種 | データサイエンス情報局\nQ-Q プロットの縦軸，横軸の関係をアニメーションにしたもの:\n引用: 【統計学】Q-Q プロットの仕組みをアニメーションで理解する。 - Qiita\nやってみる 検証コード全体はコチラ:\nGoogle Colab: https://colab.research.google.com/drive/1wSn2s6tbKpCUa6Gbi7zMsIzWZzTCkT_-?usp=sharing\nimport:\n1 2 3 4 5 import numpy as np import matplotlib.pyplot as plt import japanize_matplotlib import scipy.stats as st from scipy.special import ndtri 正規分布からランダムサンプリングしたデータが正規分布と類似しているか調べる 縦軸 サンプリングしたデータのヒストグラム:\n1 2 3 4 5 6 7 8 9 10 11 12 N = 200 # データ件数 MEAN = 10 # 平均 STD = 3 # 標準偏差 data = np.random.normal(loc=MEAN, scale=STD, size=N) plt.title(f\u0026#34;正規分布からランダムサンプリングしたプロットのヒストグラム\\n（平均={MEAN}，標準偏差={STD}）\u0026#34;) plt.xlabel(\u0026#34;階級\u0026#34;) plt.ylabel(\u0026#34;度数\u0026#34;) plt.hist(data, bins=20) plt.grid(True) plt.show() データの分位数:\n1 2 3 4 5 6 7 8 9 10 11 sorted_data = np.sort(data) x = np.linspace(0, 1, N) plt.figure(figsize=(5, 5)) plt.title(\u0026#34;正規分布からランダムサンプリングしたプロットの分位数\u0026#34;) plt.xlabel(\u0026#34;分位数\u0026#34;) plt.ylabel(\u0026#34;値\u0026#34;) plt.xlim(0, 1) plt.scatter(x, sorted_data) plt.grid(True) plt.show() 横軸 今回の理論分布は正規分布なので，正規分布の確率密度関数（＝正規累積分布関数）の逆関数を用いる．\n正規累積分布:\n1 2 3 4 5 6 7 8 9 x = np.linspace(-STD, STD, N) y_cdf = st.norm.cdf(x) plt.figure(figsize=(5, 5)) plt.title(f\u0026#34;正規累積分布関数\\n（定義域=[{-STD}, {STD}]）\u0026#34;) plt.xlabel(\u0026#34;x\u0026#34;) plt.ylabel(\u0026#34;y\u0026#34;) plt.scatter(x, y_cdf) plt.grid(True) 正規累積分布関数の逆関数:\n1 2 3 4 5 6 7 8 9 x = np.linspace(0, 1, N) inv_norm = ndtri(x) plt.figure(figsize=(5, 5)) plt.title(f\u0026#34;正規累積分布関数の逆関数\\n（定義域=[{0}, {1}]）\u0026#34;) plt.xlabel(\u0026#34;x\u0026#34;) plt.ylabel(\u0026#34;y\u0026#34;) plt.scatter(x, inv_norm) plt.grid(True) Q-Q プロット 1 2 3 4 5 6 plt.figure(figsize=(5, 5)) plt.title(f\u0026#34;Q-Qプロット\u0026#34;) plt.xlabel(\u0026#34;理論分布\u0026#34;) plt.ylabel(\u0026#34;対象データの分布\u0026#34;) plt.scatter(inv_norm, sorted_data) plt.grid(True) グラフが一直線になっていることが分かり，対象データの確率分布が正規分布に類似していることが確認できた．\n個人的な理解 同じ分布なら，ソートして分位数で可視化したときの分布も同じはず その場合，同じデータを x 軸，y 軸両方にプロットするのと同じなので，そのプロットは $y=x$ 的な感じになる 理論分布の分位数プロットは累積確率関数が使える 「なら，理論分布の関数から分位数プロット生成してもいけるのでは？」と思ってやってみたけど，Q-Q プロット生成時の逆関数値が分からなくて詰んだ… 実用 SciPy の stats.probplot() を使えば簡単に Q-Q プロットを作成できる．\n1 2 3 4 fig = plt.subplots(figsize=(5, 5)) st.probplot(sorted_data, dist=\u0026#34;norm\u0026#34;, plot=plt) plt.show() 参考記事 【Python】正規分布に従っているかを調べる手法 3 種 | データサイエンス情報局 正規 Q-Q プロット | 統計用語集 | 統計 WEB 【統計学】Q-Q プロットの仕組みをアニメーションで理解する。 - Qiita Q-Q プロット - Wikipedia ","date":"2023-01-07T15:00:00Z","permalink":"https://yamamoto-yuta.github.io/p/qq-plot-study-notes/","title":"Q-Qプロット勉強メモ"},{"content":" ✏️ 編集\nはじめに Selenium+Python 環境を Docker で作った際のメモ．基本的に下記の記事を参考に行った:\n参考記事: 第 662 回　Docker+Selenium Server で Web ブラウザ自動操作環境を作る | gihyo.jp\nまた，記事中のコードは下記リポジトリに上がっている:\nリポジトリ: https://github.com/yamamoto-yuta/selenium-on-docker-sample\n手順 1. Docker イメージを pull 今回はスクレイピングできれば OK だったので standalone-chrome を pull した\n1 $ docker pull selenium/standalone-chrome 2. 素のイメージには pip と selenium が入っていないので，入れたイメージを Dockerfile で作成 1 2 3 4 5 6 7 FROM selenium/standalone-chrome USER root RUN apt-get update \u0026amp;\u0026amp; apt-get upgrade -y \u0026amp;\u0026amp; apt install -y python3-pip USER 1200 RUN pip3 install selenium なお， apt コマンドを使おうとしたら Permission denied と言われたので，一時的に root ユーザにしている:\n1 2 3 4 5 6 7 =\u0026gt; ERROR [2/3] RUN apt-get update \u0026amp;\u0026amp; apt-get upgrade -y \u0026amp;\u0026amp; apt install -y python3-pip 1.0s ------ \u0026gt; [2/3] RUN apt-get update \u0026amp;\u0026amp; apt-get upgrade -y \u0026amp;\u0026amp; apt install -y python3-pip: #0 0.900 Reading package lists... #0 0.925 E: List directory /var/lib/apt/lists/partial is missing. - Acquire (13: Permission denied) ------ failed to solve: executor failed running [/bin/sh -c apt-get update \u0026amp;\u0026amp; apt-get upgrade -y \u0026amp;\u0026amp; apt install -y python3-pip]: exit code: 100 3. 環境設定を docker-compose.yml にまとめる 1 2 3 4 5 6 7 8 9 10 11 version: \u0026#34;3.9\u0026#34; services: app: build: . image: \u0026#34;selenium-on-docker-sample\u0026#34; container_name: \u0026#34;selenium-on-docker-sample\u0026#34; volumes: - /dev/shm:/dev/shm - .:/usr/src/app working_dir: /usr/src/app ポイントは下記の volumes 設定．この設定ではホストのメモリ領域 /dev/shm をマウントしている．これをしておかないとメモリ不足で正常に動作しないことがあるらしい:\n1 2 volumes: - /dev/shm:/dev/shm 参考: Selenium を docker で動かすと異様に遅い 特定サイトで落ちる場合の対処法 │ wonwon eater\nなお，上記の方法はホスト OS が Linux の場合に使える方法で，他の OS の場合は直接サイズを指定する方法があるらしい:\n1 2 3 build: context: . shm_size: \u0026#34;2gb\u0026#34; 参考: Selenium を docker で動かすと異様に遅い 特定サイトで落ちる場合の対処法 │ wonwon eater\n公式ドキュメント:\nStart a Docker container with Firefox 1 docker run -d -p 4444:4444 -p 7900:7900 --shm-size=\u0026#34;2g\u0026#34; selenium/standalone-firefox:4.7.2-20221219 （中略） ☝️ When executing docker run for an image that contains a browser please use the flag \u0026ndash;shm-size=2g to use the host\u0026rsquo;s shared memory.\n引用: SeleniumHQ/docker-selenium: Docker images for Selenium Grid\n3. コンテナを起動して中に入る 1 2 $ docker compose up $ docker exec -it \u0026lt;CONTAINER_ID\u0026gt; bash 4. スクレイピングスクリプトを実行 今回は下記のようなスクレイピングスクリプト sample.py を作成した．内容としては，「webdriver」でググって検索結果のページタイトルを標準出力する．\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import time from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.common.keys import Keys # Chromeのオプション options = webdriver.ChromeOptions() driver = webdriver.Chrome(\u0026#39;chromedriver\u0026#39;, options=options) try: # 要素の待機時間を最大10秒に設定 driver.implicitly_wait(10) # http://www.google.com を開く driver.get(\u0026#34;http://www.google.com\u0026#34;) # 検索ボックスに「webdriver」と入力して検索 driver.find_element(By.NAME, \u0026#34;q\u0026#34;).send_keys(\u0026#34;webdriver\u0026#34; + Keys.ENTER) time.sleep(5) # 検索結果のタイトルを取得して出力 element_titles = driver.find_elements(By.TAG_NAME, \u0026#34;h3\u0026#34;) for element_title in element_titles: print(element_title.text) except: import traceback traceback.print_exc() finally: # Chromeを終了 input(\u0026#34;何かキーを押すと終了します...\u0026#34;) driver.quit() 実行結果:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 seluser@aefbc6616615:/usr/src/app$ python3 sample.py WebDriver - Selenium WebDriver を使用して Microsoft Edge を自動化する WebDriver - MDN Web Docs - Mozilla WebDriver について私が知っていること (2017 年版) 10分で理解する Selenium - Qiita ChromeDriver - WebDriver for Chrome 7. WebDriver API — Selenium Python Bindings 2 ドキュメント WebDriverマウスとキーボードイベント Pythonで自動化しよう！ ー Selenium Webdriverを ... 何かキーを押すと終了します... 過程で調べたこと /dev/shm って何？ tmpfs という Linux マシンのメモリに作成できるファイルシステムのマウントポイントの 1 つ．tmpfs は一見 RAM ディスクっぽいが，tmpfs はファイルシステムのためフォーマットが不要という違いがある（そのため，あらかじめ容量を確保する必要が無く，使用した分だけメモリを消費する）．\n/dev/shm を利用するには，好きなディレクトリをマウントする．\n参考: tmpfs - Linux 技術者認定 LinuC | LPI-Japan\nSelenium は 3 系と 4 系で書き方が変わっている 元記事 では find_elements_by_* 系メソッドが用いられていたが，それらはバージョン 4.3.0 廃止されており，現在は下記のような書き方になっている模様:\n3 系:\n1 driver.find_elements_by_class_name(\u0026#34;content\u0026#34;) 4 系:\n1 2 3 # 引数にまとめて書くやり方に統一される from selenium.webdriver.common.by import By driver.find_elements(By.CLASS_NAME, \u0026#34;content\u0026#34;) 引用: 【Selenium】急に AttributeError: \u0026lsquo;WebDriver\u0026rsquo; object has no attribute が起きた - Qiita\n","date":"2022-12-30T15:00:00Z","permalink":"https://yamamoto-yuta.github.io/p/selenium-python-environment-docker-memo/","title":"Selenium+Python環境をDockerで作ったときのメモ"},{"content":" ✏️ 編集\n３行で SlackDeck は複数の \u0026lt;iframe\u0026gt; に Web 版 Slack を表示するため，通知が来ると多重で音が鳴ってしまう この問題を解決するために色々調べてみたところ， Slack の通知は Notification API を用いて行われていることが分かった しかし， \u0026lt;iframe\u0026gt; の通知許可はメインフレームの通知許可から行うべきであることも分かり，多重で音が鳴っている挙動が適切な挙動ということになってしまった SlackDeck とは？ Slack のチャンネルを横に並べられる Chrome 拡張機能\nhttps://chrome.google.com/webstore/detail/slackdeck/cocnkjpcbmoopfpmogblnjpjdfcaohod\n何が問題だったか？ SlackDeck は，メインの Slack を表示する \u0026lt;body\u0026gt; とカラムとして Slack を表示する \u0026lt;iframe\u0026gt; で構成されている．図にすると次の通り:\nこの状態で Slack に通知が来ると， \u0026lt;body\u0026gt; と全ての \u0026lt;iframe\u0026gt; で通知音が鳴ってしまい，多重で通知音が鳴ってしまう．\nこれが原因で SlackDeck を Chrome から削除してしまうユーザもいたため，今回，修正を試みた次第．\n調べて分かったこと Slack では通知の送信に Notification API を利用している ウェブ通知の最も顕著な用途の一つが、ウェブベースのメールや IRC アプリケーションにおいて、新しいメッセージを受信したときに、ユーザーがほかのアプリケーションで何かをしていても通知をする必要がある場合です。これには数多くの事例が存在し、例えば Slack などがあります。 引用: 通知 API の使用 - Web API | MDN\n\u0026lt;iframe\u0026gt; から通知許可を求めるメソッド Notification.requestPermission() は Chrome から非推奨と言われている Remove the ability to call Notification.requestPermission() from non-main frames. This change will align the requirements for notification permission with that of push notifications, easing friction for developers. It allows us to unify notification and push permissions. 引用: Remove Usage of Notifications from iFrames - Chrome Platform Status\nこの非推奨宣言に対応した事例を見てみると，代わりにトップレベルのフレームから許可を要求するか新しいウィンドウで開くのが良いらしい 参考: Notification.requestPermission from iframe deprecated · Issue #17 · amazon-connect/amazon-connect-streams\n以上より， \u0026lt;body\u0026gt; で表示している Slack の通知を許可したならば \u0026lt;iframe\u0026gt; で表示している Slack も許可されているのが適切．つまり，多重で通知音が鳴っている挙動が適切となる．\nどうする？ どうしよう…\n","date":"2022-12-19T15:00:00Z","permalink":"https://yamamoto-yuta.github.io/p/problem-with-slackdeck-notification-duplication/","title":"SlackDeckの通知多重で鳴っちゃう問題で詰んだ話"},{"content":" ✏️ 編集\n公式ドキュメント:\nThe Trello REST API API Introduction 参考記事:\nTrelloAPI+GAS で Trello のカード移動を Slack に通知する仕組みを作った話 - トレタ開発者ブログ 【Trello】Rest API の備忘録 Discord の Webhook URL を取得 普通に用意\nTrello の API キー、トークンを取得 Trello にログインしている状態で次のページにアクセス 開発者向け API キー\nAPI キー、トークンを取得する API キー: パーソナルキー の欄にある英数字の羅列 トークン: トークン へアクセス アプリケーションにアカウントへのアクセスを許可 発行されたトークンをメモ 下記コマンドを実行してレスポンスが返ってきていれば OK 1 2 curl --request GET \\ --url \u0026#39;https://api.trello.com/1/members/me/boards?key={APIKey}\u0026amp;token={APIToken}\u0026#39; GAS と連携 通知用チャンネルを作成（権限に Bot を追加しておかないと、Bot から通知できないので注意） GAS プロジェクトを作成 GAS プロジェクト: trello_notifier_bot\nGAS から Discord へ通知を送れるかテスト Discord の Webhook URL は環境変数的なものなので、プロジェクト設定からスクリプトプロパティへ追加\nサンプルコード:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 function myFunction() { const scriptProps = PropertiesService.getScriptProperties().getProperties(); const payload = { content: \u0026#34;content\u0026#34;, embeds: [ { title: \u0026#34;title\u0026#34;, description: \u0026#34;description\u0026#34;, }, ], }; const payloads = [ { url: scriptProps.DISCORD_WEBHOOK_URL, contentType: \u0026#34;application/json\u0026#34;, payload: JSON.stringify(payload), }, ]; UrlFetchApp.fetchAll(payloads); } 動作結果: Trello に Webhook を登録する 下記 POST を送信する。 callbackURL には GAS プロジェクトをデプロイしたときに発行される URL を入れる。 idModel は変更を検知したいボードの ID を入れる。\n1 2 3 4 5 6 7 8 curl -X POST -H \u0026#34;Content-Type: application/json\u0026#34; \\ https://api.trello.com/1/tokens/{APIToken}/webhooks/ \\ -d \u0026#39;{ \u0026#34;key\u0026#34;: \u0026#34;{APIKey}\u0026#34;, \u0026#34;callbackURL\u0026#34;: \u0026#34;http://www.mywebsite.com/trelloCallback\u0026#34;, \u0026#34;idModel\u0026#34;:\u0026#34;4d5ea62fd76aa1136000000c\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;My first webhook\u0026#34; }\u0026#39; 引用: https://developer.atlassian.com/cloud/trello/guides/rest-api/webhooks/#creating-a-webhook\nうまくいくと、下記コードの場合、登録したボードに変更を加えると doPost という文字列が Discord へ送信される。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 function doPost(e) { postToDiscord(\u0026#34;doPost\u0026#34;); } function postToDiscord(content) { const payload = { content: content, }; const payloads = [ { url: scriptProps.DISCORD_WEBHOOK_URL, contentType: \u0026#34;application/json\u0026#34;, payload: JSON.stringify(payload), }, ]; UrlFetchApp.fetchAll(payloads); } callbackURL の URL は全て大文字なので注意（間違えると、 Value isn't a string. というメッセージが返ってくる）\nWhen creating a webhook, the error \u0026ldquo;Value isn\u0026rsquo;t a string.\u0026rdquo; - Trello - The Atlassian Developer Community\n次の手順で Webhook の登録を行えるようにした:\n新しいデプロイ \u0026gt; アクセスできるユーザ: 自分のみ にしてデプロイ createWebhook() を実行 デプロイを管理 \u0026gt; アクセスできるユーザ: 全員 に変更 Trello のボードに変更を加えた時、Discord へ通知が来れば OK 手順 1 で アクセスできるユーザ: 自分のみ する理由は、全体公開にすると 403 エラーが返ってくるかららしい。\n参考: GAS を使って trello webhook を受ける時のハマりどころ - Qiita\n1 回作成された Webhook を再度作ろうとするとエラーになる。 新しいデプロイ を実施することで暫定的に回避できる。\nGAS 変更の反映方法 GAS のコードを変更したら 新しいデプロイ を行わないと反映されない。ただし、 新しいデプロイ をすると Callback URL が変わってしまう。\nその場合、 デプロイを管理 から新バージョンとしてデプロイすることで、URL を変更せずに反映できる。\n参考:\n【Web】GAS の HTML ファイルが「スクリプト関数が見つかりません：doGet」と出て表示されないときに確認すること【Google Apps Script】 - 映画と旅行とエンジニア GAS の Web アプリで URL を変えずに新バージョンを公開する（新エディタ） - make it easy doPost(e) で受け取る情報 Action Types Object Definitions 受け取った情報に Action ID があるので、それを使ってアクション詳細を取得するのが良さそう\nThe Trello REST API\n例１）カードのリストを移動した場合:\n{ \"id\": \"63712c0f23c9cc02ffa935ef\", \"idMemberCreator\": \"5da3f38080e88b1af8e8ff86\", \"data\": { \"card\": { \"idList\": \"5dd692ca0897377466449231\", \"id\": \"627bc1e708099f5b7124c099\", \"name\": \"1曲目の前に名乗り, 挨拶と常套句（余裕があったら）\", \"idShort\": 26, \"shortLink\": \"cs179j1u\" }, \"old\": { \"idList\": \"627bc1c16397f33d596253c0\" }, \"board\": { \"id\": \"5dd692c956a9247b4140e18b\", \"name\": \"2022秋ライブ\", \"shortLink\": \"szHdDf00\" }, \"listBefore\": { \"id\": \"627bc1c16397f33d596253c0\", \"name\": \"やりたいこと\" }, \"listAfter\": { \"id\": \"5dd692ca0897377466449231\", \"name\": \"やること\" } }, \"appCreator\": null, \"type\": \"updateCard\", \"date\": \"2022-11-13T17:40:31.715Z\", \"limits\": null, \"display\": { \"translationKey\": \"action_move_card_from_list_to_list\", \"entities\": { \"card\": { \"type\": \"card\", \"idList\": \"5dd692ca0897377466449231\", \"id\": \"627bc1e708099f5b7124c099\", \"shortLink\": \"cs179j1u\", \"text\": \"1曲目の前に名乗り, 挨拶と常套句（余裕があったら）\" }, \"listBefore\": { \"type\": \"list\", \"id\": \"627bc1c16397f33d596253c0\", \"text\": \"やりたいこと\" }, \"listAfter\": { \"type\": \"list\", \"id\": \"5dd692ca0897377466449231\", \"text\": \"やること\" }, \"memberCreator\": { \"type\": \"member\", \"id\": \"5da3f38080e88b1af8e8ff86\", \"username\": \"user36408094\", \"text\": \"山本雄太\" } } }, \"memberCreator\": { \"id\": \"5da3f38080e88b1af8e8ff86\", \"activityBlocked\": false, \"avatarHash\": \"bd843173354efbec0932501d2c787a46\", \"avatarUrl\": \"https://trello-members.s3.amazonaws.com/5da3f38080e88b1af8e8ff86/bd843173354efbec0932501d2c787a46\", \"fullName\": \"山本雄太\", \"idMemberReferrer\": null, \"initials\": \"山本太\", \"nonPublic\": {}, \"nonPublicAvailable\": true, \"username\": \"user36408094\" } } 例２）同一リスト内でカードを入れ替えた場合:\n{ \"id\": \"63712d7e1d8da00421bd3234\", \"idMemberCreator\": \"5da3f38080e88b1af8e8ff86\", \"data\": { \"card\": { \"pos\": 229375, \"id\": \"627bc2098e68668fe44d5219\", \"name\": \"背景と照明であわせる\", \"idShort\": 28, \"shortLink\": \"htmAcLHf\" }, \"old\": { \"pos\": 131071 }, \"board\": { \"id\": \"5dd692c956a9247b4140e18b\", \"name\": \"2022秋ライブ\", \"shortLink\": \"szHdDf00\" }, \"list\": { \"id\": \"627bc1c16397f33d596253c0\", \"name\": \"やりたいこと\" } }, \"appCreator\": null, \"type\": \"updateCard\", \"date\": \"2022-11-13T17:46:38.819Z\", \"limits\": null, \"display\": { \"translationKey\": \"action_moved_card_higher\", \"entities\": { \"card\": { \"type\": \"card\", \"pos\": 229375, \"id\": \"627bc2098e68668fe44d5219\", \"shortLink\": \"htmAcLHf\", \"text\": \"背景と照明であわせる\" }, \"memberCreator\": { \"type\": \"member\", \"id\": \"5da3f38080e88b1af8e8ff86\", \"username\": \"user36408094\", \"text\": \"山本雄太\" } } }, \"memberCreator\": { \"id\": \"5da3f38080e88b1af8e8ff86\", \"activityBlocked\": false, \"avatarHash\": \"bd843173354efbec0932501d2c787a46\", \"avatarUrl\": \"https://trello-members.s3.amazonaws.com/5da3f38080e88b1af8e8ff86/bd843173354efbec0932501d2c787a46\", \"fullName\": \"山本雄太\", \"idMemberReferrer\": null, \"initials\": \"山本太\", \"nonPublic\": {}, \"nonPublicAvailable\": true, \"username\": \"user36408094\" } } 例３）カードにコメントを追加した場合:\n{ \"id\": \"63712df1630c6c05daf96fd0\", \"idMemberCreator\": \"5da3f38080e88b1af8e8ff86\", \"data\": { \"text\": \"aaaaa\", \"textData\": { \"emoji\": {} }, \"card\": { \"id\": \"627bc1e708099f5b7124c099\", \"name\": \"1曲目の前に名乗り, 挨拶と常套句（余裕があったら）\", \"idShort\": 26, \"shortLink\": \"cs179j1u\" }, \"board\": { \"id\": \"5dd692c956a9247b4140e18b\", \"name\": \"2022秋ライブ\", \"shortLink\": \"szHdDf00\" }, \"list\": { \"id\": \"5dd692ca0897377466449231\", \"name\": \"やること\" } }, \"appCreator\": null, \"type\": \"commentCard\", \"date\": \"2022-11-13T17:48:33.824Z\", \"limits\": { \"reactions\": { \"perAction\": { \"status\": \"ok\", \"disableAt\": 900, \"warnAt\": 720 }, \"uniquePerAction\": { \"status\": \"ok\", \"disableAt\": 17, \"warnAt\": 14 } } }, \"display\": { \"translationKey\": \"action_comment_on_card\", \"entities\": { \"contextOn\": { \"type\": \"translatable\", \"translationKey\": \"action_on\", \"hideIfContext\": true, \"idContext\": \"627bc1e708099f5b7124c099\" }, \"card\": { \"type\": \"card\", \"hideIfContext\": true, \"id\": \"627bc1e708099f5b7124c099\", \"shortLink\": \"cs179j1u\", \"text\": \"1曲目の前に名乗り, 挨拶と常套句（余裕があったら）\" }, \"comment\": { \"type\": \"comment\", \"text\": \"aaaaa\" }, \"memberCreator\": { \"type\": \"member\", \"id\": \"5da3f38080e88b1af8e8ff86\", \"username\": \"user36408094\", \"text\": \"山本雄太\" } } }, \"memberCreator\": { \"id\": \"5da3f38080e88b1af8e8ff86\", \"activityBlocked\": false, \"avatarHash\": \"bd843173354efbec0932501d2c787a46\", \"avatarUrl\": \"https://trello-members.s3.amazonaws.com/5da3f38080e88b1af8e8ff86/bd843173354efbec0932501d2c787a46\", \"fullName\": \"山本雄太\", \"idMemberReferrer\": null, \"initials\": \"山本太\", \"nonPublic\": {}, \"nonPublicAvailable\": true, \"username\": \"user36408094\" } } 例４）さらにコメントを追加した場合:\n{ \"id\": \"63712e485c9137001535ed3f\", \"idMemberCreator\": \"5da3f38080e88b1af8e8ff86\", \"data\": { \"text\": \"bbbbb\", \"textData\": { \"emoji\": {} }, \"card\": { \"id\": \"627bc1e708099f5b7124c099\", \"name\": \"1曲目の前に名乗り, 挨拶と常套句（余裕があったら）\", \"idShort\": 26, \"shortLink\": \"cs179j1u\" }, \"board\": { \"id\": \"5dd692c956a9247b4140e18b\", \"name\": \"2022秋ライブ\", \"shortLink\": \"szHdDf00\" }, \"list\": { \"id\": \"5dd692ca0897377466449231\", \"name\": \"やること\" } }, \"appCreator\": null, \"type\": \"commentCard\", \"date\": \"2022-11-13T17:50:00.381Z\", \"limits\": { \"reactions\": { \"perAction\": { \"status\": \"ok\", \"disableAt\": 900, \"warnAt\": 720 }, \"uniquePerAction\": { \"status\": \"ok\", \"disableAt\": 17, \"warnAt\": 14 } } }, \"display\": { \"translationKey\": \"action_comment_on_card\", \"entities\": { \"contextOn\": { \"type\": \"translatable\", \"translationKey\": \"action_on\", \"hideIfContext\": true, \"idContext\": \"627bc1e708099f5b7124c099\" }, \"card\": { \"type\": \"card\", \"hideIfContext\": true, \"id\": \"627bc1e708099f5b7124c099\", \"shortLink\": \"cs179j1u\", \"text\": \"1曲目の前に名乗り, 挨拶と常套句（余裕があったら）\" }, \"comment\": { \"type\": \"comment\", \"text\": \"bbbbb\" }, \"memberCreator\": { \"type\": \"member\", \"id\": \"5da3f38080e88b1af8e8ff86\", \"username\": \"user36408094\", \"text\": \"山本雄太\" } } }, \"memberCreator\": { \"id\": \"5da3f38080e88b1af8e8ff86\", \"activityBlocked\": false, \"avatarHash\": \"bd843173354efbec0932501d2c787a46\", \"avatarUrl\": \"https://trello-members.s3.amazonaws.com/5da3f38080e88b1af8e8ff86/bd843173354efbec0932501d2c787a46\", \"fullName\": \"山本雄太\", \"idMemberReferrer\": null, \"initials\": \"山本太\", \"nonPublic\": {}, \"nonPublicAvailable\": true, \"username\": \"user36408094\" } } ","date":"2022-10-30T15:00:00Z","permalink":"https://yamamoto-yuta.github.io/p/trello-discord-integration-notes/","title":"Trello + Discord 連携メモ"},{"content":" ✏️ 編集\n方法 skicka を使う rclone を使う skicka を使う skicka って何？ Google ドライブを CLI 上で操作できるツール → 公式リポジトリ\n導入方法 基本的に公式 README通りで OK 2021/6/25 現在、手順 5 の認証のところでエラーが出る（issue514）ので、次の記事の手順を実行して解決する skicka の『「Google でログイン」機能が一時的に無効』を一時的に解決する - Qiita 公開ステータスが「テスト」のままだと エラー 403: access_denied が出るので、「本番環境に push」しておくこと 導入してみた感想 ls だけでも毎回 3 秒以上かかるので使い物にならない…何故… 参考記事 GDrive を CLI で使う　- skicka - - Qiita リンク等まとめ｜ Google Drive をコマンドラインで扱う - Qiita rclone を使う Rclone rclone を使用した Google Drive のバックアップ - Qiita ","date":"2021-06-24T15:00:00Z","permalink":"https://yamamoto-yuta.github.io/p/using-google-drive-via-cli/","title":"GoogleドライブをCLIで使えるようにしてみる"},{"content":" ✏️ 編集\n風邪薬の効果を検証 新しく開発した風邪薬に「回復を早める効果があるか」を検証する\nデータ収集 風邪を引いている人を 100 人集めて薬を飲んでもらい，回復日数を計測する\n効果を確かめる 統計的検定の方針 収集した「投薬者の平均回復日数」とあらかじめ分かっている「一般人の平均回復日数」の差を比較する．この差が一定以上であれば薬に効果があるとみなす．\n※ 一般人の風邪の回復日数はその分布（回復の平均日数、回復日数の個人差など) があらかじめ分っているものとする\n統計的検定の手順 帰無仮説：「薬に効果がない」＝「薬を飲んでも飲まなくても回復日数に変わりはない」 対立仮説：「薬に効果がある」＝「薬を飲んだ方が回復日数が短くなる」\n測定した 100 人の平均回復日数を算出 帰無仮説の確率分布（＝一般人の回復日数の確率分布）に従う環境で，測定した値になる確率を算出 算出した確率が低かった場合，「薬に効果がない」という帰無仮説を棄却し「薬に効果がある」という対立仮説を採用する 判断に使う数値 「一定以上の差がある」（有意差が認められた）という判断を下すためには数値的判断基準が必要\np 値：帰無仮説が正しい場合，観測値と等しいかそれより極端な値を取る確率 有意水準：p 値がどのくらい小さい場合に帰無仮説を棄却するか，その閾値\np 値が有意水準を下回る＝有意差が認められた\n風邪薬のケースの場合 p 値 一般人から 100 人をランダムに選んだ場合の確率分布 p 値\n平均回復日数が 3.7 日以下になる確率＝ 20% 平均回復日数が 3.2 日以下になる確率＝ 10% 平均回復日数が 2.9 日 以下になる確率 ＝ 5% 有意水準 検定前にあらかじめ決めておく\n今回は有意水準＝ 5%に設定 判定方法 「薬を飲んだ人」100 人の平均が 3.7 日だった場合 → それは「一般人」100 人でも 20%の確率であり得る値＝薬に効果があるとは言えない（有意差が認められなかった）\n「薬を飲んだ人」100 人の平均が 2.9 日以下だった場合 → それは「一般人」100 人でも 5%以下の確率でしかあり得ない値＝薬に効果があると言える（有意差が認められた）\np 値の解釈に関する注意点 p 値は効果を示すものではない 今回の風邪薬の場合では平均回復日数が 3.7 日以下になる確率＝ 20%だったが，サンプル数がもっと多かったり少なかったりすればこの 20%という値は変わる\n何回も試行して有効な p 値を出してはいけない p 値=0.05 の場合，100 回に 5 回しか起こらない低い確率を前提としているので，何回も試行するとその前提が崩れてしまう おみくじで大吉が出るまで何回も引くようなもの\np 値だけで判断してはいけない p 値はあくまで指標の一つにすぎない その他の統計手法，実務上の考慮点などを鑑みて最終的な判断を下す必要がある\n帰無仮説が棄却されなくても，帰無仮説が正しいということにはならない 帰無仮説が棄却されなかった＝有意差がが認められなかった つまり，帰無仮説が正しいということを示したわけではない\n参考文献 統計的有意 p 値って何ですか？ ","date":"2020-07-01T15:00:00Z","permalink":"https://yamamoto-yuta.github.io/p/statistical-significance-and-p-value/","title":"統計的有意とp値"},{"content":" ✏️ 編集\n時系列解析とは？ 時系列データ（毎日の売り上げ，日々の気温 etc…）を分析する手法 過去のデータから未来のデータを予測することが可能\n回帰分析で予測すればいいのでは？ 時系列データの回帰分析には注意が必要\n回帰分析：　最小二乗法を用いて傾きや切片を推定 → 最小二乗法が使える条件：　データの独立性\n独立でないデータとは？ → 過去の値に合わせて現在の値も変わってしまう（自己相関のある）データ\n例）「昨日の売り上げが多ければ，今日の売り上げも多くなる」 時系列データは独立でないことが多い　→ 回帰分析ではうまくいかない場合が多い\n時系列データへの回帰分析フローチャート 引用：https://logics-of-blue.com/time-series-regression/\n誤差分布には正規分布を仮定（正規分布以外の場合，状態空間モデル等での対応が必要） 検定の方法はいろいろあり、このフローチャート通りにしてもうまくいかない or このやり方以外のうまい方法がある場合もあるので、あくまで参考程度 検定 単位根検定 時系列データが単根過程かどうかを判定する検定\n定常過程 期待値（平均）と自己相関が常に一定の確率過程 大局的に見て真っ平 - 例）ホワイトノイズ 単位根過程 原系列$y_t$が非定常過程で，差分系列$\\Delta y_t = y_t - y_{t-1}$が定常過程の時系列 例）ランダムウォーク 単位根過程に回帰分析を行うとどうなるか？ 有意な回帰係数が得られる しかし，無関係な２つの系列に対して有意な回帰が行えているのはおかしい したがって，単位根過程に回帰分析を行うのは良くない → 検定で時系列データが単位根過程がどうか調べる必要がある\n単位根検定 ADF 検定 帰無仮説：単位根過程である 対立仮説：単位根過程でない として，p 値\u0026lt;0.05 で帰無仮説棄却＝単位根過程でないとする単位根検定\n参考文献 Python による時系列分析の基礎 時系列解析_理論編 時系列データへの回帰分析 ","date":"2020-06-30T15:00:00Z","permalink":"https://yamamoto-yuta.github.io/p/notes-for-time-series-analysis-basics/","title":"時系列解析の触りだけメモ"},{"content":" ✏️ 編集\nPageRank とは？ Google の検索エンジンに用いられている Web ページの価値評価を行うアルゴリズム 価値評価には Web ページのリンク関係を用いている 直感的な理解 Web ページの中からランダムにページを 1 つ決める そのページに貼られているリンクからランダムにページを遷移していく ページ遷移を繰り返して、最終的にどのページを開いている確率が高いか？ その確率が PageRank\n重要なページはたくさん引用されるので，↑ の確率が高くなる．\n計算方法 1. 各ページのリンク関係から遷移確率行列 P を作成 例えば，各ページのリンク関係が ↓ みたいな場合，\n$P$ は ↓ になる\n$$ P = \\left( \\begin{array}{ccc} 0 \u0026amp; 0 \u0026amp; 1/2 \u0026amp; 1/2 \u0026amp; 0 \\ 1/2 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1/2 \u0026amp; 0 \\ 1/2 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1/2 \\ 1/4 \u0026amp; 1/4 \u0026amp; 1/4 \u0026amp; 0 \u0026amp; 1/4 \\ 1/2 \u0026amp; 1/2 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\end{array} \\right) $$\n行方向：遷移元のページ 列方向：遷移先のページ 要素：遷移元ページから遷移先ページへの遷移確率 ex. ページ 1→ ページ 3 への遷移確率は $p_{13} = 1/2$ 2. 遷移確率行列の固有値と固有ベクトルを計算する 2.1. なぜ固有値と固有ベクトルを計算するのか？ $t$ 回遷移した時にページ $i$ を開いている確率を $x_{t_i}$ として，各ページでの確率をベクトル $\\vec{x_t}$ を用いて次のようにまとめる．\n$$ \\vec{x_t} = \\left( \\begin{array}{ccc} x_{t_1} \u0026amp; x_{t_2} \u0026amp; \\cdots \u0026amp; x_{t_i} \u0026amp; \\cdots \\end{array} \\right) $$\nしたがって，t+1 回目の遷移は次のように表せる．\n$$ \\vec{x_{t+1}} = \\vec{x_t} P $$\nこのようにして何回も遷移を繰り返していくと$\\vec{x_t}$は一定に収束する．つまり，\n$$ \\vec{x_t} = \\vec{x_t} P $$\nとなる．\n2.2. 固有値と固有ベクトルを計算する 行列 $P$ の固有値 $\\lambda$ ，固有ベクト $\\vec{x}$ は次のような関係にある．\n$$ \\vec{x} P = \\lambda \\vec{x} $$\nしたがって，固有値 $\\lambda = 1$ に対応する固有ベクトルが PageRank となる（※ PageRank は確率なので後で正規化する必要あり）．\n補足 ↑ で説明した計算方法は最もシンプルなものであり，実際にはもう少し改良がなされている．以下にその改良をいくつか挙げる．\n改良１　ランダムジャンプ ↓ のようなネットワークグラフだと ② と ④ で閉ループが形成されていて，まともに PageRank が計算できない．そのため，一定確率でリンクされていないページへジャンプするようになっている．\n改良２　カテゴリの概念 実際のネットサーフィンでは同じカテゴリのページ間の方が，違うカテゴリのページ間より遷移する可能性が高いと考えられる（例：サッカーのページを開いている人が次に開くページは，同じスポーツカテゴリである野球のページの方が，全く異なるカテゴリである手芸のページより可能性が高い）．\n参考文献 PageRank アルゴリズムおよびそれに関連する研究について いまさら学ぶ PageRank アルゴリズム ","date":"2020-03-02T15:00:00Z","permalink":"https://yamamoto-yuta.github.io/p/pagerank-memo/","title":"PageRankメモ"}]